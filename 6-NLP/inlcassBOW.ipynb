{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ed11fda2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/elloyd/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/elloyd/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/elloyd/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /Users/elloyd/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger_eng to\n",
      "[nltk_data]     /Users/elloyd/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger_eng is already up-to-\n",
      "[nltk_data]       date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Ensure NLTK components are available\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('averaged_perceptron_tagger_eng')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "438b5fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"NLP.txt\", \"r\") as file:\n",
    "    raw_text = file.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6bce6c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punct_table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "def get_wordnet_pos(tag):\n",
    "    if tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN  # default to noun\n",
    "\n",
    "def preprocess(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    print(f\"Tokens: {tokens}\")  # Debugging line\n",
    "\n",
    "    tokens = [t.lower().translate(punct_table) for t in tokens if t.isalnum()]\n",
    "    print(f\"Tokens after punctuation removal: {tokens}\")  #\n",
    "    \n",
    "    tokens = [t for t in tokens if t not in stop_words]\n",
    "    print(f\"Tokens after stopword removal: {tokens}\")  # Debugging line\n",
    "\n",
    "    pos_tags = pos_tag(tokens)\n",
    "    print(f\"POS tags: {pos_tags}\")\n",
    "\n",
    "    tokens = [lemmatizer.lemmatize(t, get_wordnet_pos(tag)) for t, tag in pos_tags]\n",
    "    print(f\"Tokens after lemmatization: {tokens}\")  # Debugging line\n",
    "    print(\"\")\n",
    "\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b830b9ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokens: ['Until', 'recently', ',', 'the', 'conventional', 'wisdom', 'was', 'that', 'while', 'AI', 'was', 'better', 'than', 'humans', 'at', 'data-driven', 'decision', 'making', 'tasks', ',', 'it', 'was', 'still', 'inferior', 'to', 'humans', 'for', 'cognitive', 'and', 'creative', 'ones', '.', 'But', 'in', 'the', 'past', 'two', 'years', 'language-based', 'AI', 'has', 'advanced', 'by', 'leaps', 'and', 'bounds', ',', 'changing', 'common', 'notions', 'of', 'what', 'this', 'technology', 'can', 'do', '.']\n",
      "Tokens after punctuation removal: ['until', 'recently', 'the', 'conventional', 'wisdom', 'was', 'that', 'while', 'ai', 'was', 'better', 'than', 'humans', 'at', 'decision', 'making', 'tasks', 'it', 'was', 'still', 'inferior', 'to', 'humans', 'for', 'cognitive', 'and', 'creative', 'ones', 'but', 'in', 'the', 'past', 'two', 'years', 'ai', 'has', 'advanced', 'by', 'leaps', 'and', 'bounds', 'changing', 'common', 'notions', 'of', 'what', 'this', 'technology', 'can', 'do']\n",
      "Tokens after stopword removal: ['recently', 'conventional', 'wisdom', 'ai', 'better', 'humans', 'decision', 'making', 'tasks', 'still', 'inferior', 'humans', 'cognitive', 'creative', 'ones', 'past', 'two', 'years', 'ai', 'advanced', 'leaps', 'bounds', 'changing', 'common', 'notions', 'technology']\n",
      "POS tags: [('recently', 'RB'), ('conventional', 'JJ'), ('wisdom', 'NN'), ('ai', 'VBP'), ('better', 'JJR'), ('humans', 'NNS'), ('decision', 'NN'), ('making', 'NN'), ('tasks', 'NNS'), ('still', 'RB'), ('inferior', 'JJ'), ('humans', 'NNS'), ('cognitive', 'JJ'), ('creative', 'JJ'), ('ones', 'NNS'), ('past', 'IN'), ('two', 'CD'), ('years', 'NNS'), ('ai', 'VBP'), ('advanced', 'JJ'), ('leaps', 'NNS'), ('bounds', 'VBZ'), ('changing', 'VBG'), ('common', 'JJ'), ('notions', 'NNS'), ('technology', 'NN')]\n",
      "Tokens after lemmatization: ['recently', 'conventional', 'wisdom', 'ai', 'good', 'human', 'decision', 'making', 'task', 'still', 'inferior', 'human', 'cognitive', 'creative', 'one', 'past', 'two', 'year', 'ai', 'advanced', 'leap', 'bound', 'change', 'common', 'notion', 'technology']\n",
      "\n",
      "Tokens: ['The', 'most', 'visible', 'advances', 'have', 'been', 'in', 'what', '’', 's', 'called', '“', 'natural', 'language', 'processing', '”', '(', 'NLP', ')', ',', 'the', 'branch', 'of', 'AI', 'focused', 'on', 'how', 'computers', 'can', 'process', 'language', 'like', 'humans', 'do', '.', 'It', 'has', 'been', 'used', 'to', 'write', 'an', 'article', 'for', 'The', 'Guardian', ',', 'and', 'AI-authored', 'blog', 'posts', 'have', 'gone', 'viral', '—', 'feats', 'that', 'weren', '’', 't', 'possible', 'a', 'few', 'years', 'ago', '.', 'AI', 'even', 'excels', 'at', 'cognitive', 'tasks', 'like', 'programming', 'where', 'it', 'is', 'able', 'to', 'generate', 'programs', 'for', 'simple', 'video', 'games', 'from', 'human', 'instructions', '.']\n",
      "Tokens after punctuation removal: ['the', 'most', 'visible', 'advances', 'have', 'been', 'in', 'what', 's', 'called', 'natural', 'language', 'processing', 'nlp', 'the', 'branch', 'of', 'ai', 'focused', 'on', 'how', 'computers', 'can', 'process', 'language', 'like', 'humans', 'do', 'it', 'has', 'been', 'used', 'to', 'write', 'an', 'article', 'for', 'the', 'guardian', 'and', 'blog', 'posts', 'have', 'gone', 'viral', 'feats', 'that', 'weren', 't', 'possible', 'a', 'few', 'years', 'ago', 'ai', 'even', 'excels', 'at', 'cognitive', 'tasks', 'like', 'programming', 'where', 'it', 'is', 'able', 'to', 'generate', 'programs', 'for', 'simple', 'video', 'games', 'from', 'human', 'instructions']\n",
      "Tokens after stopword removal: ['visible', 'advances', 'called', 'natural', 'language', 'processing', 'nlp', 'branch', 'ai', 'focused', 'computers', 'process', 'language', 'like', 'humans', 'used', 'write', 'article', 'guardian', 'blog', 'posts', 'gone', 'viral', 'feats', 'possible', 'years', 'ago', 'ai', 'even', 'excels', 'cognitive', 'tasks', 'like', 'programming', 'able', 'generate', 'programs', 'simple', 'video', 'games', 'human', 'instructions']\n",
      "POS tags: [('visible', 'JJ'), ('advances', 'NNS'), ('called', 'VBD'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('nlp', 'JJ'), ('branch', 'NN'), ('ai', 'VBP'), ('focused', 'JJ'), ('computers', 'NNS'), ('process', 'JJ'), ('language', 'NN'), ('like', 'IN'), ('humans', 'NNS'), ('used', 'VBN'), ('write', 'JJ'), ('article', 'NN'), ('guardian', 'JJ'), ('blog', 'NN'), ('posts', 'VBZ'), ('gone', 'VBN'), ('viral', 'JJ'), ('feats', 'NNS'), ('possible', 'JJ'), ('years', 'NNS'), ('ago', 'IN'), ('ai', 'RB'), ('even', 'RB'), ('excels', 'RBR'), ('cognitive', 'JJ'), ('tasks', 'NNS'), ('like', 'IN'), ('programming', 'VBG'), ('able', 'JJ'), ('generate', 'NN'), ('programs', 'NNS'), ('simple', 'JJ'), ('video', 'JJ'), ('games', 'NNS'), ('human', 'JJ'), ('instructions', 'NNS')]\n",
      "Tokens after lemmatization: ['visible', 'advance', 'call', 'natural', 'language', 'processing', 'nlp', 'branch', 'ai', 'focused', 'computer', 'process', 'language', 'like', 'human', 'use', 'write', 'article', 'guardian', 'blog', 'post', 'go', 'viral', 'feat', 'possible', 'year', 'ago', 'ai', 'even', 'excels', 'cognitive', 'task', 'like', 'program', 'able', 'generate', 'program', 'simple', 'video', 'game', 'human', 'instruction']\n",
      "\n",
      "Tokens: ['Yet', 'while', 'these', 'stunts', 'may', 'be', 'attention', 'grabbing', ',', 'are', 'they', 'really', 'indicative', 'of', 'what', 'this', 'tech', 'can', 'do', 'for', 'businesses', '?']\n",
      "Tokens after punctuation removal: ['yet', 'while', 'these', 'stunts', 'may', 'be', 'attention', 'grabbing', 'are', 'they', 'really', 'indicative', 'of', 'what', 'this', 'tech', 'can', 'do', 'for', 'businesses']\n",
      "Tokens after stopword removal: ['yet', 'stunts', 'may', 'attention', 'grabbing', 'really', 'indicative', 'tech', 'businesses']\n",
      "POS tags: [('yet', 'RB'), ('stunts', 'NNS'), ('may', 'MD'), ('attention', 'NN'), ('grabbing', 'VBG'), ('really', 'RB'), ('indicative', 'JJ'), ('tech', 'NN'), ('businesses', 'NNS')]\n",
      "Tokens after lemmatization: ['yet', 'stunt', 'may', 'attention', 'grab', 'really', 'indicative', 'tech', 'business']\n",
      "\n",
      "Tokens: ['What', 'NLP', 'Can', 'Do']\n",
      "Tokens after punctuation removal: ['what', 'nlp', 'can', 'do']\n",
      "Tokens after stopword removal: ['nlp']\n",
      "POS tags: [('nlp', 'NN')]\n",
      "Tokens after lemmatization: ['nlp']\n",
      "\n",
      "Tokens: ['The', 'best', 'known', 'natural', 'language', 'processing', 'tool', 'is', 'GPT-3', ',', 'from', 'OpenAI', ',', 'which', 'uses', 'AI', 'and', 'statistics', 'to', 'predict', 'the', 'next', 'word', 'in', 'a', 'sentence', 'based', 'on', 'the', 'preceding', 'words', '.', 'NLP', 'practitioners', 'call', 'tools', 'like', 'this', '“', 'language', 'models', ',', '”', 'and', 'they', 'can', 'be', 'used', 'for', 'simple', 'analytics', 'tasks', ',', 'such', 'as', 'classifying', 'documents', 'and', 'analyzing', 'the', 'sentiment', 'in', 'blocks', 'of', 'text', ',', 'as', 'well', 'as', 'more', 'advanced', 'tasks', ',', 'such', 'as', 'answering', 'questions', 'and', 'summarizing', 'reports', '.', 'Language', 'models', 'are', 'already', 'reshaping', 'traditional', 'text', 'analytics', ',', 'but', 'GPT-3', 'was', 'an', 'especially', 'pivotal', 'language', 'model', 'because', ',', 'at', '10x', 'larger', 'than', 'any', 'previous', 'model', 'upon', 'release', ',', 'it', 'was', 'the', 'first', 'large', 'language', 'model', ',', 'which', 'enabled', 'it', 'to', 'perform', 'even', 'more', 'advanced', 'tasks', 'like', 'programming', 'and', 'solving', 'high', 'school–level', 'math', 'problems', '.', 'The', 'latest', 'version', ',', 'called', 'InstructGPT', ',', 'has', 'been', 'fine-tuned', 'by', 'humans', 'to', 'generate', 'responses', 'that', 'are', 'much', 'better', 'aligned', 'with', 'human', 'values', 'and', 'user', 'intentions', ',', 'and', 'Google', '’', 's', 'latest', 'model', 'shows', 'further', 'impressive', 'breakthroughs', 'on', 'language', 'and', 'reasoning', '.']\n",
      "Tokens after punctuation removal: ['the', 'best', 'known', 'natural', 'language', 'processing', 'tool', 'is', 'from', 'openai', 'which', 'uses', 'ai', 'and', 'statistics', 'to', 'predict', 'the', 'next', 'word', 'in', 'a', 'sentence', 'based', 'on', 'the', 'preceding', 'words', 'nlp', 'practitioners', 'call', 'tools', 'like', 'this', 'language', 'models', 'and', 'they', 'can', 'be', 'used', 'for', 'simple', 'analytics', 'tasks', 'such', 'as', 'classifying', 'documents', 'and', 'analyzing', 'the', 'sentiment', 'in', 'blocks', 'of', 'text', 'as', 'well', 'as', 'more', 'advanced', 'tasks', 'such', 'as', 'answering', 'questions', 'and', 'summarizing', 'reports', 'language', 'models', 'are', 'already', 'reshaping', 'traditional', 'text', 'analytics', 'but', 'was', 'an', 'especially', 'pivotal', 'language', 'model', 'because', 'at', '10x', 'larger', 'than', 'any', 'previous', 'model', 'upon', 'release', 'it', 'was', 'the', 'first', 'large', 'language', 'model', 'which', 'enabled', 'it', 'to', 'perform', 'even', 'more', 'advanced', 'tasks', 'like', 'programming', 'and', 'solving', 'high', 'math', 'problems', 'the', 'latest', 'version', 'called', 'instructgpt', 'has', 'been', 'by', 'humans', 'to', 'generate', 'responses', 'that', 'are', 'much', 'better', 'aligned', 'with', 'human', 'values', 'and', 'user', 'intentions', 'and', 'google', 's', 'latest', 'model', 'shows', 'further', 'impressive', 'breakthroughs', 'on', 'language', 'and', 'reasoning']\n",
      "Tokens after stopword removal: ['best', 'known', 'natural', 'language', 'processing', 'tool', 'openai', 'uses', 'ai', 'statistics', 'predict', 'next', 'word', 'sentence', 'based', 'preceding', 'words', 'nlp', 'practitioners', 'call', 'tools', 'like', 'language', 'models', 'used', 'simple', 'analytics', 'tasks', 'classifying', 'documents', 'analyzing', 'sentiment', 'blocks', 'text', 'well', 'advanced', 'tasks', 'answering', 'questions', 'summarizing', 'reports', 'language', 'models', 'already', 'reshaping', 'traditional', 'text', 'analytics', 'especially', 'pivotal', 'language', 'model', '10x', 'larger', 'previous', 'model', 'upon', 'release', 'first', 'large', 'language', 'model', 'enabled', 'perform', 'even', 'advanced', 'tasks', 'like', 'programming', 'solving', 'high', 'math', 'problems', 'latest', 'version', 'called', 'instructgpt', 'humans', 'generate', 'responses', 'much', 'better', 'aligned', 'human', 'values', 'user', 'intentions', 'google', 'latest', 'model', 'shows', 'impressive', 'breakthroughs', 'language', 'reasoning']\n",
      "POS tags: [('best', 'RB'), ('known', 'VBN'), ('natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('tool', 'NN'), ('openai', 'JJ'), ('uses', 'VBZ'), ('ai', 'VBP'), ('statistics', 'NNS'), ('predict', 'VBP'), ('next', 'JJ'), ('word', 'NN'), ('sentence', 'NN'), ('based', 'VBN'), ('preceding', 'NN'), ('words', 'NNS'), ('nlp', 'JJ'), ('practitioners', 'NNS'), ('call', 'VBP'), ('tools', 'NNS'), ('like', 'IN'), ('language', 'NN'), ('models', 'NNS'), ('used', 'VBN'), ('simple', 'JJ'), ('analytics', 'NNS'), ('tasks', 'NNS'), ('classifying', 'VBG'), ('documents', 'NNS'), ('analyzing', 'VBG'), ('sentiment', 'NN'), ('blocks', 'NNS'), ('text', 'RB'), ('well', 'RB'), ('advanced', 'JJ'), ('tasks', 'NNS'), ('answering', 'VBG'), ('questions', 'NNS'), ('summarizing', 'VBG'), ('reports', 'NNS'), ('language', 'NN'), ('models', 'NNS'), ('already', 'RB'), ('reshaping', 'VBG'), ('traditional', 'JJ'), ('text', 'NN'), ('analytics', 'NNS'), ('especially', 'RB'), ('pivotal', 'JJ'), ('language', 'NN'), ('model', 'NN'), ('10x', 'CD'), ('larger', 'JJR'), ('previous', 'JJ'), ('model', 'NN'), ('upon', 'IN'), ('release', 'NN'), ('first', 'RB'), ('large', 'JJ'), ('language', 'NN'), ('model', 'NN'), ('enabled', 'VBD'), ('perform', 'RB'), ('even', 'RB'), ('advanced', 'JJ'), ('tasks', 'NNS'), ('like', 'IN'), ('programming', 'VBG'), ('solving', 'VBG'), ('high', 'JJ'), ('math', 'NN'), ('problems', 'NNS'), ('latest', 'JJS'), ('version', 'NN'), ('called', 'VBN'), ('instructgpt', 'NN'), ('humans', 'NNS'), ('generate', 'VBP'), ('responses', 'NNS'), ('much', 'RB'), ('better', 'RBR'), ('aligned', 'VBN'), ('human', 'JJ'), ('values', 'NNS'), ('user', 'VBP'), ('intentions', 'NNS'), ('google', 'VBP'), ('latest', 'JJS'), ('model', 'NN'), ('shows', 'NNS'), ('impressive', 'VBP'), ('breakthroughs', 'NNS'), ('language', 'NN'), ('reasoning', 'VBG')]\n",
      "Tokens after lemmatization: ['best', 'know', 'natural', 'language', 'processing', 'tool', 'openai', 'use', 'ai', 'statistic', 'predict', 'next', 'word', 'sentence', 'base', 'preceding', 'word', 'nlp', 'practitioner', 'call', 'tool', 'like', 'language', 'model', 'use', 'simple', 'analytics', 'task', 'classify', 'document', 'analyze', 'sentiment', 'block', 'text', 'well', 'advanced', 'task', 'answer', 'question', 'summarize', 'report', 'language', 'model', 'already', 'reshape', 'traditional', 'text', 'analytics', 'especially', 'pivotal', 'language', 'model', '10x', 'large', 'previous', 'model', 'upon', 'release', 'first', 'large', 'language', 'model', 'enable', 'perform', 'even', 'advanced', 'task', 'like', 'program', 'solve', 'high', 'math', 'problem', 'late', 'version', 'call', 'instructgpt', 'human', 'generate', 'response', 'much', 'well', 'align', 'human', 'value', 'user', 'intention', 'google', 'late', 'model', 'show', 'impressive', 'breakthrough', 'language', 'reason']\n",
      "\n",
      "Tokens: ['For', 'businesses', ',', 'the', 'three', 'areas', 'where', 'GPT-3', 'has', 'appeared', 'most', 'promising', 'are', 'writing', ',', 'coding', ',', 'and', 'discipline-specific', 'reasoning', '.', 'OpenAI', ',', 'the', 'Microsoft-funded', 'creator', 'of', 'GPT-3', ',', 'has', 'developed', 'a', 'GPT-3-based', 'language', 'model', 'intended', 'to', 'act', 'as', 'an', 'assistant', 'for', 'programmers', 'by', 'generating', 'code', 'from', 'natural', 'language', 'input', '.', 'This', 'tool', ',', 'Codex', ',', 'is', 'already', 'powering', 'products', 'like', 'Copilot', 'for', 'Microsoft', '’', 's', 'subsidiary', 'GitHub', 'and', 'is', 'capable', 'of', 'creating', 'a', 'basic', 'video', 'game', 'simply', 'by', 'typing', 'instructions', '.', 'This', 'transformative', 'capability', 'was', 'already', 'expected', 'to', 'change', 'the', 'nature', 'of', 'how', 'programmers', 'do', 'their', 'jobs', ',', 'but', 'models', 'continue', 'to', 'improve', '—', 'the', 'latest', 'from', 'Google', '’', 's', 'DeepMind', 'AI', 'lab', ',', 'for', 'example', ',', 'demonstrates', 'the', 'critical', 'thinking', 'and', 'logic', 'skills', 'necessary', 'to', 'outperform', 'most', 'humans', 'in', 'programming', 'competitions', '.']\n",
      "Tokens after punctuation removal: ['for', 'businesses', 'the', 'three', 'areas', 'where', 'has', 'appeared', 'most', 'promising', 'are', 'writing', 'coding', 'and', 'reasoning', 'openai', 'the', 'creator', 'of', 'has', 'developed', 'a', 'language', 'model', 'intended', 'to', 'act', 'as', 'an', 'assistant', 'for', 'programmers', 'by', 'generating', 'code', 'from', 'natural', 'language', 'input', 'this', 'tool', 'codex', 'is', 'already', 'powering', 'products', 'like', 'copilot', 'for', 'microsoft', 's', 'subsidiary', 'github', 'and', 'is', 'capable', 'of', 'creating', 'a', 'basic', 'video', 'game', 'simply', 'by', 'typing', 'instructions', 'this', 'transformative', 'capability', 'was', 'already', 'expected', 'to', 'change', 'the', 'nature', 'of', 'how', 'programmers', 'do', 'their', 'jobs', 'but', 'models', 'continue', 'to', 'improve', 'the', 'latest', 'from', 'google', 's', 'deepmind', 'ai', 'lab', 'for', 'example', 'demonstrates', 'the', 'critical', 'thinking', 'and', 'logic', 'skills', 'necessary', 'to', 'outperform', 'most', 'humans', 'in', 'programming', 'competitions']\n",
      "Tokens after stopword removal: ['businesses', 'three', 'areas', 'appeared', 'promising', 'writing', 'coding', 'reasoning', 'openai', 'creator', 'developed', 'language', 'model', 'intended', 'act', 'assistant', 'programmers', 'generating', 'code', 'natural', 'language', 'input', 'tool', 'codex', 'already', 'powering', 'products', 'like', 'copilot', 'microsoft', 'subsidiary', 'github', 'capable', 'creating', 'basic', 'video', 'game', 'simply', 'typing', 'instructions', 'transformative', 'capability', 'already', 'expected', 'change', 'nature', 'programmers', 'jobs', 'models', 'continue', 'improve', 'latest', 'google', 'deepmind', 'ai', 'lab', 'example', 'demonstrates', 'critical', 'thinking', 'logic', 'skills', 'necessary', 'outperform', 'humans', 'programming', 'competitions']\n",
      "POS tags: [('businesses', 'NNS'), ('three', 'CD'), ('areas', 'NNS'), ('appeared', 'VBD'), ('promising', 'VBG'), ('writing', 'VBG'), ('coding', 'VBG'), ('reasoning', 'VBG'), ('openai', 'JJ'), ('creator', 'NN'), ('developed', 'VBD'), ('language', 'NN'), ('model', 'NN'), ('intended', 'VBN'), ('act', 'NN'), ('assistant', 'NN'), ('programmers', 'NNS'), ('generating', 'VBG'), ('code', 'NN'), ('natural', 'JJ'), ('language', 'NN'), ('input', 'NN'), ('tool', 'NN'), ('codex', 'NN'), ('already', 'RB'), ('powering', 'VBG'), ('products', 'NNS'), ('like', 'IN'), ('copilot', 'NN'), ('microsoft', 'JJ'), ('subsidiary', 'NN'), ('github', 'NN'), ('capable', 'JJ'), ('creating', 'VBG'), ('basic', 'JJ'), ('video', 'NN'), ('game', 'NN'), ('simply', 'RB'), ('typing', 'VBG'), ('instructions', 'NNS'), ('transformative', 'JJ'), ('capability', 'NN'), ('already', 'RB'), ('expected', 'VBN'), ('change', 'NN'), ('nature', 'NN'), ('programmers', 'NNS'), ('jobs', 'NNS'), ('models', 'NNS'), ('continue', 'VBP'), ('improve', 'VB'), ('latest', 'JJS'), ('google', 'NN'), ('deepmind', 'NN'), ('ai', 'NN'), ('lab', 'NN'), ('example', 'NN'), ('demonstrates', 'VBZ'), ('critical', 'JJ'), ('thinking', 'VBG'), ('logic', 'JJ'), ('skills', 'NNS'), ('necessary', 'JJ'), ('outperform', 'NN'), ('humans', 'NNS'), ('programming', 'VBG'), ('competitions', 'NNS')]\n",
      "Tokens after lemmatization: ['business', 'three', 'area', 'appear', 'promise', 'write', 'cod', 'reason', 'openai', 'creator', 'develop', 'language', 'model', 'intend', 'act', 'assistant', 'programmer', 'generate', 'code', 'natural', 'language', 'input', 'tool', 'codex', 'already', 'power', 'product', 'like', 'copilot', 'microsoft', 'subsidiary', 'github', 'capable', 'create', 'basic', 'video', 'game', 'simply', 'type', 'instruction', 'transformative', 'capability', 'already', 'expect', 'change', 'nature', 'programmer', 'job', 'model', 'continue', 'improve', 'late', 'google', 'deepmind', 'ai', 'lab', 'example', 'demonstrate', 'critical', 'think', 'logic', 'skill', 'necessary', 'outperform', 'human', 'program', 'competition']\n",
      "\n",
      "Tokens: ['Models', 'like', 'GPT-3', 'are', 'considered', 'to', 'be', 'foundation', 'models', '—', 'an', 'emerging', 'AI', 'research', 'area', '—', 'which', 'also', 'work', 'for', 'other', 'types', 'of', 'data', 'such', 'as', 'images', 'and', 'video', '.', 'Foundation', 'models', 'can', 'even', 'be', 'trained', 'on', 'multiple', 'forms', 'of', 'data', 'at', 'the', 'same', 'time', ',', 'like', 'OpenAI', '’', 's', 'DALL·E', '2', ',', 'which', 'is', 'trained', 'on', 'language', 'and', 'images', 'to', 'generate', 'high-resolution', 'renderings', 'of', 'imaginary', 'scenes', 'or', 'objects', 'simply', 'from', 'text', 'prompts', '.', 'Due', 'to', 'their', 'potential', 'to', 'transform', 'the', 'nature', 'of', 'cognitive', 'work', ',', 'economists', 'expect', 'that', 'foundation', 'models', 'may', 'affect', 'every', 'part', 'of', 'the', 'economy', 'and', 'could', 'lead', 'to', 'increases', 'in', 'economic', 'growth', 'similar', 'to', 'the', 'industrial', 'revolution', '.']\n",
      "Tokens after punctuation removal: ['models', 'like', 'are', 'considered', 'to', 'be', 'foundation', 'models', 'an', 'emerging', 'ai', 'research', 'area', 'which', 'also', 'work', 'for', 'other', 'types', 'of', 'data', 'such', 'as', 'images', 'and', 'video', 'foundation', 'models', 'can', 'even', 'be', 'trained', 'on', 'multiple', 'forms', 'of', 'data', 'at', 'the', 'same', 'time', 'like', 'openai', 's', '2', 'which', 'is', 'trained', 'on', 'language', 'and', 'images', 'to', 'generate', 'renderings', 'of', 'imaginary', 'scenes', 'or', 'objects', 'simply', 'from', 'text', 'prompts', 'due', 'to', 'their', 'potential', 'to', 'transform', 'the', 'nature', 'of', 'cognitive', 'work', 'economists', 'expect', 'that', 'foundation', 'models', 'may', 'affect', 'every', 'part', 'of', 'the', 'economy', 'and', 'could', 'lead', 'to', 'increases', 'in', 'economic', 'growth', 'similar', 'to', 'the', 'industrial', 'revolution']\n",
      "Tokens after stopword removal: ['models', 'like', 'considered', 'foundation', 'models', 'emerging', 'ai', 'research', 'area', 'also', 'work', 'types', 'data', 'images', 'video', 'foundation', 'models', 'even', 'trained', 'multiple', 'forms', 'data', 'time', 'like', 'openai', '2', 'trained', 'language', 'images', 'generate', 'renderings', 'imaginary', 'scenes', 'objects', 'simply', 'text', 'prompts', 'due', 'potential', 'transform', 'nature', 'cognitive', 'work', 'economists', 'expect', 'foundation', 'models', 'may', 'affect', 'every', 'part', 'economy', 'could', 'lead', 'increases', 'economic', 'growth', 'similar', 'industrial', 'revolution']\n",
      "POS tags: [('models', 'NNS'), ('like', 'IN'), ('considered', 'VBN'), ('foundation', 'NN'), ('models', 'NNS'), ('emerging', 'VBG'), ('ai', 'JJ'), ('research', 'NN'), ('area', 'NN'), ('also', 'RB'), ('work', 'VBP'), ('types', 'NNS'), ('data', 'NNS'), ('images', 'NNS'), ('video', 'VBP'), ('foundation', 'NN'), ('models', 'NNS'), ('even', 'RB'), ('trained', 'VBD'), ('multiple', 'JJ'), ('forms', 'NNS'), ('data', 'VBP'), ('time', 'NN'), ('like', 'IN'), ('openai', '$'), ('2', 'CD'), ('trained', 'JJ'), ('language', 'NN'), ('images', 'NNS'), ('generate', 'VBP'), ('renderings', 'NNS'), ('imaginary', 'JJ'), ('scenes', 'NNS'), ('objects', 'NNS'), ('simply', 'RB'), ('text', 'JJ'), ('prompts', 'NNS'), ('due', 'JJ'), ('potential', 'JJ'), ('transform', 'NN'), ('nature', 'NN'), ('cognitive', 'JJ'), ('work', 'NN'), ('economists', 'NNS'), ('expect', 'VBP'), ('foundation', 'NN'), ('models', 'NNS'), ('may', 'MD'), ('affect', 'VB'), ('every', 'DT'), ('part', 'NN'), ('economy', 'NN'), ('could', 'MD'), ('lead', 'VB'), ('increases', 'NNS'), ('economic', 'JJ'), ('growth', 'NN'), ('similar', 'JJ'), ('industrial', 'JJ'), ('revolution', 'NN')]\n",
      "Tokens after lemmatization: ['model', 'like', 'consider', 'foundation', 'model', 'emerge', 'ai', 'research', 'area', 'also', 'work', 'type', 'data', 'image', 'video', 'foundation', 'model', 'even', 'train', 'multiple', 'form', 'data', 'time', 'like', 'openai', '2', 'trained', 'language', 'image', 'generate', 'rendering', 'imaginary', 'scene', 'object', 'simply', 'text', 'prompt', 'due', 'potential', 'transform', 'nature', 'cognitive', 'work', 'economist', 'expect', 'foundation', 'model', 'may', 'affect', 'every', 'part', 'economy', 'could', 'lead', 'increase', 'economic', 'growth', 'similar', 'industrial', 'revolution']\n",
      "\n",
      "Tokens: ['A', 'Language-Based', 'AI', 'Research', 'Assistant']\n",
      "Tokens after punctuation removal: ['a', 'ai', 'research', 'assistant']\n",
      "Tokens after stopword removal: ['ai', 'research', 'assistant']\n",
      "POS tags: [('ai', 'JJ'), ('research', 'NN'), ('assistant', 'NN')]\n",
      "Tokens after lemmatization: ['ai', 'research', 'assistant']\n",
      "\n",
      "Tokens: ['In', 'my', 'own', 'work', ',', 'I', '’', 've', 'been', 'looking', 'at', 'how', 'GPT-3-based', 'tools', 'can', 'assist', 'researchers', 'in', 'the', 'research', 'process', '.', 'I', 'am', 'currently', 'working', 'with', 'Ought', ',', 'a', 'San', 'Francisco', 'company', 'developing', 'an', 'open-ended', 'reasoning', 'tool', '(', 'called', 'Elicit', ')', 'that', 'is', 'intended', 'to', 'help', 'researchers', 'answer', 'questions', 'in', 'minutes', 'or', 'hours', 'instead', 'of', 'weeks', 'or', 'months', '.', 'Elicit', 'is', 'designed', 'for', 'a', 'growing', 'number', 'of', 'specific', 'tasks', 'relevant', 'to', 'research', ',', 'like', 'summarization', ',', 'data', 'labeling', ',', 'rephrasing', ',', 'brainstorming', ',', 'and', 'literature', 'reviews', '.']\n",
      "Tokens after punctuation removal: ['in', 'my', 'own', 'work', 'i', 've', 'been', 'looking', 'at', 'how', 'tools', 'can', 'assist', 'researchers', 'in', 'the', 'research', 'process', 'i', 'am', 'currently', 'working', 'with', 'ought', 'a', 'san', 'francisco', 'company', 'developing', 'an', 'reasoning', 'tool', 'called', 'elicit', 'that', 'is', 'intended', 'to', 'help', 'researchers', 'answer', 'questions', 'in', 'minutes', 'or', 'hours', 'instead', 'of', 'weeks', 'or', 'months', 'elicit', 'is', 'designed', 'for', 'a', 'growing', 'number', 'of', 'specific', 'tasks', 'relevant', 'to', 'research', 'like', 'summarization', 'data', 'labeling', 'rephrasing', 'brainstorming', 'and', 'literature', 'reviews']\n",
      "Tokens after stopword removal: ['work', 'looking', 'tools', 'assist', 'researchers', 'research', 'process', 'currently', 'working', 'ought', 'san', 'francisco', 'company', 'developing', 'reasoning', 'tool', 'called', 'elicit', 'intended', 'help', 'researchers', 'answer', 'questions', 'minutes', 'hours', 'instead', 'weeks', 'months', 'elicit', 'designed', 'growing', 'number', 'specific', 'tasks', 'relevant', 'research', 'like', 'summarization', 'data', 'labeling', 'rephrasing', 'brainstorming', 'literature', 'reviews']\n",
      "POS tags: [('work', 'NN'), ('looking', 'VBG'), ('tools', 'NNS'), ('assist', 'JJ'), ('researchers', 'NNS'), ('research', 'NN'), ('process', 'NN'), ('currently', 'RB'), ('working', 'VBG'), ('ought', 'MD'), ('san', 'VB'), ('francisco', 'JJ'), ('company', 'NN'), ('developing', 'VBG'), ('reasoning', 'VBG'), ('tool', 'NN'), ('called', 'VBN'), ('elicit', 'NN'), ('intended', 'VBN'), ('help', 'NN'), ('researchers', 'NNS'), ('answer', 'VBP'), ('questions', 'NNS'), ('minutes', 'NNS'), ('hours', 'NNS'), ('instead', 'RB'), ('weeks', 'NNS'), ('months', 'NNS'), ('elicit', 'RB'), ('designed', 'VBN'), ('growing', 'VBG'), ('number', 'NN'), ('specific', 'JJ'), ('tasks', 'NNS'), ('relevant', 'JJ'), ('research', 'NN'), ('like', 'IN'), ('summarization', 'NN'), ('data', 'NNS'), ('labeling', 'VBG'), ('rephrasing', 'VBG'), ('brainstorming', 'JJ'), ('literature', 'NN'), ('reviews', 'NNS')]\n",
      "Tokens after lemmatization: ['work', 'look', 'tool', 'assist', 'researcher', 'research', 'process', 'currently', 'work', 'ought', 'san', 'francisco', 'company', 'develop', 'reason', 'tool', 'call', 'elicit', 'intend', 'help', 'researcher', 'answer', 'question', 'minute', 'hour', 'instead', 'week', 'month', 'elicit', 'design', 'grow', 'number', 'specific', 'task', 'relevant', 'research', 'like', 'summarization', 'data', 'label', 'rephrase', 'brainstorming', 'literature', 'review']\n",
      "\n",
      "Tokens: ['I', '’', 've', 'found', '—', 'not', 'surprisingly', '—', 'that', 'Elicit', 'works', 'better', 'for', 'some', 'tasks', 'than', 'others', '.', 'Tasks', 'like', 'data', 'labeling', 'and', 'summarization', 'are', 'still', 'rough', 'around', 'the', 'edges', ',', 'with', 'noisy', 'results', 'and', 'spotty', 'accuracy', ',', 'but', 'research', 'from', 'Ought', 'and', 'research', 'from', 'OpenAI', 'shows', 'promise', 'for', 'the', 'future', '.']\n",
      "Tokens after punctuation removal: ['i', 've', 'found', 'not', 'surprisingly', 'that', 'elicit', 'works', 'better', 'for', 'some', 'tasks', 'than', 'others', 'tasks', 'like', 'data', 'labeling', 'and', 'summarization', 'are', 'still', 'rough', 'around', 'the', 'edges', 'with', 'noisy', 'results', 'and', 'spotty', 'accuracy', 'but', 'research', 'from', 'ought', 'and', 'research', 'from', 'openai', 'shows', 'promise', 'for', 'the', 'future']\n",
      "Tokens after stopword removal: ['found', 'surprisingly', 'elicit', 'works', 'better', 'tasks', 'others', 'tasks', 'like', 'data', 'labeling', 'summarization', 'still', 'rough', 'around', 'edges', 'noisy', 'results', 'spotty', 'accuracy', 'research', 'ought', 'research', 'openai', 'shows', 'promise', 'future']\n",
      "POS tags: [('found', 'VBN'), ('surprisingly', 'RB'), ('elicit', 'JJ'), ('works', 'NNS'), ('better', 'RBR'), ('tasks', 'NNS'), ('others', 'NNS'), ('tasks', 'VBP'), ('like', 'IN'), ('data', 'NNS'), ('labeling', 'VBG'), ('summarization', 'NN'), ('still', 'RB'), ('rough', 'JJ'), ('around', 'IN'), ('edges', 'NNS'), ('noisy', 'JJ'), ('results', 'NNS'), ('spotty', 'JJ'), ('accuracy', 'JJ'), ('research', 'NN'), ('ought', 'MD'), ('research', 'NN'), ('openai', 'NN'), ('shows', 'VBZ'), ('promise', 'VBP'), ('future', 'NN')]\n",
      "Tokens after lemmatization: ['find', 'surprisingly', 'elicit', 'work', 'well', 'task', 'others', 'task', 'like', 'data', 'label', 'summarization', 'still', 'rough', 'around', 'edge', 'noisy', 'result', 'spotty', 'accuracy', 'research', 'ought', 'research', 'openai', 'show', 'promise', 'future']\n",
      "\n",
      "Tokens: ['For', 'example', ',', 'the', 'rephrase', 'task', 'is', 'useful', 'for', 'writing', ',', 'but', 'the', 'lack', 'of', 'integration', 'with', 'word', 'processing', 'apps', 'renders', 'it', 'impractical', 'for', 'now', '.', 'Brainstorming', 'tasks', 'are', 'great', 'for', 'generating', 'ideas', 'or', 'identifying', 'overlooked', 'topics', ',', 'and', 'despite', 'the', 'noisy', 'results', 'and', 'barriers', 'to', 'adoption', ',', 'they', 'are', 'currently', 'valuable', 'for', 'a', 'variety', 'of', 'situations', '.', 'Yet', ',', 'of', 'all', 'the', 'tasks', 'Elicit', 'offers', ',', 'I', 'find', 'the', 'literature', 'review', 'the', 'most', 'useful', '.', 'Because', 'Elicit', 'is', 'an', 'AI', 'research', 'assistant', ',', 'this', 'is', 'sort', 'of', 'its', 'bread-and-butter', ',', 'and', 'when', 'I', 'need', 'to', 'start', 'digging', 'into', 'a', 'new', 'research', 'topic', ',', 'it', 'has', 'become', 'my', 'go-to', 'resource', '.']\n",
      "Tokens after punctuation removal: ['for', 'example', 'the', 'rephrase', 'task', 'is', 'useful', 'for', 'writing', 'but', 'the', 'lack', 'of', 'integration', 'with', 'word', 'processing', 'apps', 'renders', 'it', 'impractical', 'for', 'now', 'brainstorming', 'tasks', 'are', 'great', 'for', 'generating', 'ideas', 'or', 'identifying', 'overlooked', 'topics', 'and', 'despite', 'the', 'noisy', 'results', 'and', 'barriers', 'to', 'adoption', 'they', 'are', 'currently', 'valuable', 'for', 'a', 'variety', 'of', 'situations', 'yet', 'of', 'all', 'the', 'tasks', 'elicit', 'offers', 'i', 'find', 'the', 'literature', 'review', 'the', 'most', 'useful', 'because', 'elicit', 'is', 'an', 'ai', 'research', 'assistant', 'this', 'is', 'sort', 'of', 'its', 'and', 'when', 'i', 'need', 'to', 'start', 'digging', 'into', 'a', 'new', 'research', 'topic', 'it', 'has', 'become', 'my', 'resource']\n",
      "Tokens after stopword removal: ['example', 'rephrase', 'task', 'useful', 'writing', 'lack', 'integration', 'word', 'processing', 'apps', 'renders', 'impractical', 'brainstorming', 'tasks', 'great', 'generating', 'ideas', 'identifying', 'overlooked', 'topics', 'despite', 'noisy', 'results', 'barriers', 'adoption', 'currently', 'valuable', 'variety', 'situations', 'yet', 'tasks', 'elicit', 'offers', 'find', 'literature', 'review', 'useful', 'elicit', 'ai', 'research', 'assistant', 'sort', 'need', 'start', 'digging', 'new', 'research', 'topic', 'become', 'resource']\n",
      "POS tags: [('example', 'NN'), ('rephrase', 'NN'), ('task', 'NN'), ('useful', 'JJ'), ('writing', 'VBG'), ('lack', 'NN'), ('integration', 'NN'), ('word', 'NN'), ('processing', 'NN'), ('apps', 'NN'), ('renders', 'NNS'), ('impractical', 'JJ'), ('brainstorming', 'NN'), ('tasks', 'NNS'), ('great', 'JJ'), ('generating', 'VBG'), ('ideas', 'NNS'), ('identifying', 'VBG'), ('overlooked', 'VBD'), ('topics', 'NNS'), ('despite', 'IN'), ('noisy', 'JJ'), ('results', 'NNS'), ('barriers', 'NNS'), ('adoption', 'VBP'), ('currently', 'RB'), ('valuable', 'JJ'), ('variety', 'NN'), ('situations', 'NNS'), ('yet', 'RB'), ('tasks', 'NNS'), ('elicit', 'VBP'), ('offers', 'NNS'), ('find', 'VBP'), ('literature', 'NN'), ('review', 'NN'), ('useful', 'JJ'), ('elicit', 'JJ'), ('ai', 'NN'), ('research', 'NN'), ('assistant', 'NN'), ('sort', 'NN'), ('need', 'VBP'), ('start', 'VB'), ('digging', 'VBG'), ('new', 'JJ'), ('research', 'NN'), ('topic', 'NN'), ('become', 'VBN'), ('resource', 'NN')]\n",
      "Tokens after lemmatization: ['example', 'rephrase', 'task', 'useful', 'write', 'lack', 'integration', 'word', 'processing', 'apps', 'render', 'impractical', 'brainstorming', 'task', 'great', 'generate', 'idea', 'identify', 'overlook', 'topic', 'despite', 'noisy', 'result', 'barrier', 'adoption', 'currently', 'valuable', 'variety', 'situation', 'yet', 'task', 'elicit', 'offer', 'find', 'literature', 'review', 'useful', 'elicit', 'ai', 'research', 'assistant', 'sort', 'need', 'start', 'dig', 'new', 'research', 'topic', 'become', 'resource']\n",
      "\n",
      "Tokens: ['All', 'of', 'this', 'is', 'changing', 'how', 'I', 'work', '.', 'I', 'spend', 'much', 'less', 'time', 'trying', 'to', 'find', 'existing', 'content', 'relevant', 'to', 'my', 'research', 'questions', 'because', 'its', 'results', 'are', 'more', 'applicable', 'than', 'other', ',', 'more', 'traditional', 'interfaces', 'for', 'academic', 'search', 'like', 'Google', 'Scholar', '.', 'I', 'am', 'also', 'beginning', 'to', 'integrate', 'brainstorming', 'tasks', 'into', 'my', 'work', 'as', 'well', ',', 'and', 'my', 'experience', 'with', 'these', 'tools', 'has', 'inspired', 'my', 'latest', 'research', ',', 'which', 'seeks', 'to', 'utilize', 'foundation', 'models', 'for', 'supporting', 'strategic', 'planning', '.']\n",
      "Tokens after punctuation removal: ['all', 'of', 'this', 'is', 'changing', 'how', 'i', 'work', 'i', 'spend', 'much', 'less', 'time', 'trying', 'to', 'find', 'existing', 'content', 'relevant', 'to', 'my', 'research', 'questions', 'because', 'its', 'results', 'are', 'more', 'applicable', 'than', 'other', 'more', 'traditional', 'interfaces', 'for', 'academic', 'search', 'like', 'google', 'scholar', 'i', 'am', 'also', 'beginning', 'to', 'integrate', 'brainstorming', 'tasks', 'into', 'my', 'work', 'as', 'well', 'and', 'my', 'experience', 'with', 'these', 'tools', 'has', 'inspired', 'my', 'latest', 'research', 'which', 'seeks', 'to', 'utilize', 'foundation', 'models', 'for', 'supporting', 'strategic', 'planning']\n",
      "Tokens after stopword removal: ['changing', 'work', 'spend', 'much', 'less', 'time', 'trying', 'find', 'existing', 'content', 'relevant', 'research', 'questions', 'results', 'applicable', 'traditional', 'interfaces', 'academic', 'search', 'like', 'google', 'scholar', 'also', 'beginning', 'integrate', 'brainstorming', 'tasks', 'work', 'well', 'experience', 'tools', 'inspired', 'latest', 'research', 'seeks', 'utilize', 'foundation', 'models', 'supporting', 'strategic', 'planning']\n",
      "POS tags: [('changing', 'VBG'), ('work', 'NN'), ('spend', 'RB'), ('much', 'RB'), ('less', 'JJR'), ('time', 'NN'), ('trying', 'VBG'), ('find', 'VB'), ('existing', 'JJ'), ('content', 'NN'), ('relevant', 'JJ'), ('research', 'NN'), ('questions', 'NNS'), ('results', 'NNS'), ('applicable', 'JJ'), ('traditional', 'JJ'), ('interfaces', 'NNS'), ('academic', 'JJ'), ('search', 'NN'), ('like', 'IN'), ('google', 'NN'), ('scholar', 'NN'), ('also', 'RB'), ('beginning', 'VBG'), ('integrate', 'JJ'), ('brainstorming', 'NN'), ('tasks', 'NNS'), ('work', 'VBP'), ('well', 'RB'), ('experience', 'RB'), ('tools', 'NNS'), ('inspired', 'VBD'), ('latest', 'JJS'), ('research', 'NN'), ('seeks', 'VBZ'), ('utilize', 'JJ'), ('foundation', 'NN'), ('models', 'NNS'), ('supporting', 'VBG'), ('strategic', 'JJ'), ('planning', 'NN')]\n",
      "Tokens after lemmatization: ['change', 'work', 'spend', 'much', 'less', 'time', 'try', 'find', 'existing', 'content', 'relevant', 'research', 'question', 'result', 'applicable', 'traditional', 'interface', 'academic', 'search', 'like', 'google', 'scholar', 'also', 'begin', 'integrate', 'brainstorming', 'task', 'work', 'well', 'experience', 'tool', 'inspire', 'late', 'research', 'seek', 'utilize', 'foundation', 'model', 'support', 'strategic', 'planning']\n",
      "\n",
      "Tokens: ['How', 'Can', 'Organizations', 'Prepare', 'for', 'the', 'Future', '?']\n",
      "Tokens after punctuation removal: ['how', 'can', 'organizations', 'prepare', 'for', 'the', 'future']\n",
      "Tokens after stopword removal: ['organizations', 'prepare', 'future']\n",
      "POS tags: [('organizations', 'NNS'), ('prepare', 'VBP'), ('future', 'JJ')]\n",
      "Tokens after lemmatization: ['organization', 'prepare', 'future']\n",
      "\n",
      "Tokens: ['Identify', 'your', 'text', 'data', 'assets', 'and', 'determine', 'how', 'the', 'latest', 'techniques', 'can', 'be', 'leveraged', 'to', 'add', 'value', 'for', 'your', 'firm', '.']\n",
      "Tokens after punctuation removal: ['identify', 'your', 'text', 'data', 'assets', 'and', 'determine', 'how', 'the', 'latest', 'techniques', 'can', 'be', 'leveraged', 'to', 'add', 'value', 'for', 'your', 'firm']\n",
      "Tokens after stopword removal: ['identify', 'text', 'data', 'assets', 'determine', 'latest', 'techniques', 'leveraged', 'add', 'value', 'firm']\n",
      "POS tags: [('identify', 'VB'), ('text', 'NN'), ('data', 'NNS'), ('assets', 'NNS'), ('determine', 'VBP'), ('latest', 'JJS'), ('techniques', 'NNS'), ('leveraged', 'VBN'), ('add', 'VBP'), ('value', 'NN'), ('firm', 'NN')]\n",
      "Tokens after lemmatization: ['identify', 'text', 'data', 'asset', 'determine', 'late', 'technique', 'leverage', 'add', 'value', 'firm']\n",
      "\n",
      "Tokens: ['You', 'are', 'certainly', 'aware', 'of', 'the', 'value', 'of', 'data', ',', 'but', 'you', 'still', 'may', 'be', 'overlooking', 'some', 'essential', 'data', 'assets', 'if', 'you', 'are', 'not', 'utilizing', 'text', 'analytics', 'and', 'NLP', 'throughout', 'your', 'organization', '.', 'Text', 'data', 'is', 'certainly', 'valuable', 'for', 'customer', 'experience', 'management', 'and', 'understanding', 'the', 'voice', 'of', 'the', 'customer', ',', 'but', 'think', 'about', 'other', 'text', 'data', 'assets', 'in', 'your', 'organization', ':', 'emails', ',', 'analysts', '’', 'reports', ',', 'contracts', ',', 'press', 'releases', ',', 'archives', '—', 'even', 'meetings', 'and', 'phone', 'calls', 'can', 'be', 'transcribed', '.']\n",
      "Tokens after punctuation removal: ['you', 'are', 'certainly', 'aware', 'of', 'the', 'value', 'of', 'data', 'but', 'you', 'still', 'may', 'be', 'overlooking', 'some', 'essential', 'data', 'assets', 'if', 'you', 'are', 'not', 'utilizing', 'text', 'analytics', 'and', 'nlp', 'throughout', 'your', 'organization', 'text', 'data', 'is', 'certainly', 'valuable', 'for', 'customer', 'experience', 'management', 'and', 'understanding', 'the', 'voice', 'of', 'the', 'customer', 'but', 'think', 'about', 'other', 'text', 'data', 'assets', 'in', 'your', 'organization', 'emails', 'analysts', 'reports', 'contracts', 'press', 'releases', 'archives', 'even', 'meetings', 'and', 'phone', 'calls', 'can', 'be', 'transcribed']\n",
      "Tokens after stopword removal: ['certainly', 'aware', 'value', 'data', 'still', 'may', 'overlooking', 'essential', 'data', 'assets', 'utilizing', 'text', 'analytics', 'nlp', 'throughout', 'organization', 'text', 'data', 'certainly', 'valuable', 'customer', 'experience', 'management', 'understanding', 'voice', 'customer', 'think', 'text', 'data', 'assets', 'organization', 'emails', 'analysts', 'reports', 'contracts', 'press', 'releases', 'archives', 'even', 'meetings', 'phone', 'calls', 'transcribed']\n",
      "POS tags: [('certainly', 'RB'), ('aware', 'JJ'), ('value', 'NN'), ('data', 'NNS'), ('still', 'RB'), ('may', 'MD'), ('overlooking', 'VBG'), ('essential', 'JJ'), ('data', 'NNS'), ('assets', 'NNS'), ('utilizing', 'VBG'), ('text', 'JJ'), ('analytics', 'NNS'), ('nlp', 'VBP'), ('throughout', 'IN'), ('organization', 'NN'), ('text', 'NN'), ('data', 'NNS'), ('certainly', 'RB'), ('valuable', 'JJ'), ('customer', 'NN'), ('experience', 'NN'), ('management', 'NN'), ('understanding', 'JJ'), ('voice', 'NN'), ('customer', 'NN'), ('think', 'VBP'), ('text', 'IN'), ('data', 'NNS'), ('assets', 'NNS'), ('organization', 'NN'), ('emails', 'VBZ'), ('analysts', 'NNS'), ('reports', 'NNS'), ('contracts', 'NNS'), ('press', 'NN'), ('releases', 'VBZ'), ('archives', 'NNS'), ('even', 'RB'), ('meetings', 'NNS'), ('phone', 'NN'), ('calls', 'VBZ'), ('transcribed', 'RP')]\n",
      "Tokens after lemmatization: ['certainly', 'aware', 'value', 'data', 'still', 'may', 'overlook', 'essential', 'data', 'asset', 'utilize', 'text', 'analytics', 'nlp', 'throughout', 'organization', 'text', 'data', 'certainly', 'valuable', 'customer', 'experience', 'management', 'understanding', 'voice', 'customer', 'think', 'text', 'data', 'asset', 'organization', 'email', 'analyst', 'report', 'contract', 'press', 'release', 'archive', 'even', 'meeting', 'phone', 'call', 'transcribed']\n",
      "\n",
      "Tokens: ['There', 'is', 'so', 'much', 'text', 'data', ',', 'and', 'you', 'don', '’', 't', 'need', 'advanced', 'models', 'like', 'GPT-3', 'to', 'extract', 'its', 'value', '.', 'Hugging', 'Face', ',', 'an', 'NLP', 'startup', ',', 'recently', 'released', 'AutoNLP', ',', 'a', 'new', 'tool', 'that', 'automates', 'training', 'models', 'for', 'standard', 'text', 'analytics', 'tasks', 'by', 'simply', 'uploading', 'your', 'data', 'to', 'the', 'platform', '.', 'The', 'data', 'still', 'needs', 'labels', ',', 'but', 'far', 'fewer', 'than', 'in', 'other', 'applications', '.', 'Because', 'many', 'firms', 'have', 'made', 'ambitious', 'bets', 'on', 'AI', 'only', 'to', 'struggle', 'to', 'drive', 'value', 'into', 'the', 'core', 'business', ',', 'remain', 'cautious', 'to', 'not', 'be', 'overzealous', '.', 'This', 'can', 'be', 'a', 'good', 'first', 'step', 'that', 'your', 'existing', 'machine', 'learning', 'engineers', '—', 'or', 'even', 'talented', 'data', 'scientists', '—', 'can', 'manage', '.']\n",
      "Tokens after punctuation removal: ['there', 'is', 'so', 'much', 'text', 'data', 'and', 'you', 'don', 't', 'need', 'advanced', 'models', 'like', 'to', 'extract', 'its', 'value', 'hugging', 'face', 'an', 'nlp', 'startup', 'recently', 'released', 'autonlp', 'a', 'new', 'tool', 'that', 'automates', 'training', 'models', 'for', 'standard', 'text', 'analytics', 'tasks', 'by', 'simply', 'uploading', 'your', 'data', 'to', 'the', 'platform', 'the', 'data', 'still', 'needs', 'labels', 'but', 'far', 'fewer', 'than', 'in', 'other', 'applications', 'because', 'many', 'firms', 'have', 'made', 'ambitious', 'bets', 'on', 'ai', 'only', 'to', 'struggle', 'to', 'drive', 'value', 'into', 'the', 'core', 'business', 'remain', 'cautious', 'to', 'not', 'be', 'overzealous', 'this', 'can', 'be', 'a', 'good', 'first', 'step', 'that', 'your', 'existing', 'machine', 'learning', 'engineers', 'or', 'even', 'talented', 'data', 'scientists', 'can', 'manage']\n",
      "Tokens after stopword removal: ['much', 'text', 'data', 'need', 'advanced', 'models', 'like', 'extract', 'value', 'hugging', 'face', 'nlp', 'startup', 'recently', 'released', 'autonlp', 'new', 'tool', 'automates', 'training', 'models', 'standard', 'text', 'analytics', 'tasks', 'simply', 'uploading', 'data', 'platform', 'data', 'still', 'needs', 'labels', 'far', 'fewer', 'applications', 'many', 'firms', 'made', 'ambitious', 'bets', 'ai', 'struggle', 'drive', 'value', 'core', 'business', 'remain', 'cautious', 'overzealous', 'good', 'first', 'step', 'existing', 'machine', 'learning', 'engineers', 'even', 'talented', 'data', 'scientists', 'manage']\n",
      "POS tags: [('much', 'JJ'), ('text', 'NN'), ('data', 'NNS'), ('need', 'VBP'), ('advanced', 'JJ'), ('models', 'NNS'), ('like', 'IN'), ('extract', 'JJ'), ('value', 'NN'), ('hugging', 'VBG'), ('face', 'NN'), ('nlp', 'JJ'), ('startup', 'NN'), ('recently', 'RB'), ('released', 'VBN'), ('autonlp', 'RP'), ('new', 'JJ'), ('tool', 'NN'), ('automates', 'VBZ'), ('training', 'VBG'), ('models', 'NNS'), ('standard', 'JJ'), ('text', 'IN'), ('analytics', 'NNS'), ('tasks', 'NNS'), ('simply', 'RB'), ('uploading', 'VBG'), ('data', 'NNS'), ('platform', 'NN'), ('data', 'NNS'), ('still', 'RB'), ('needs', 'VBZ'), ('labels', 'NNS'), ('far', 'RB'), ('fewer', 'JJR'), ('applications', 'NNS'), ('many', 'JJ'), ('firms', 'NNS'), ('made', 'VBD'), ('ambitious', 'JJ'), ('bets', 'NNS'), ('ai', 'VBP'), ('struggle', 'JJ'), ('drive', 'NN'), ('value', 'NN'), ('core', 'NN'), ('business', 'NN'), ('remain', 'VBP'), ('cautious', 'JJ'), ('overzealous', 'JJ'), ('good', 'JJ'), ('first', 'JJ'), ('step', 'NN'), ('existing', 'VBG'), ('machine', 'NN'), ('learning', 'VBG'), ('engineers', 'NNS'), ('even', 'RB'), ('talented', 'VBD'), ('data', 'NNS'), ('scientists', 'NNS'), ('manage', 'VBP')]\n",
      "Tokens after lemmatization: ['much', 'text', 'data', 'need', 'advanced', 'model', 'like', 'extract', 'value', 'hug', 'face', 'nlp', 'startup', 'recently', 'release', 'autonlp', 'new', 'tool', 'automate', 'train', 'model', 'standard', 'text', 'analytics', 'task', 'simply', 'upload', 'data', 'platform', 'data', 'still', 'need', 'label', 'far', 'few', 'application', 'many', 'firm', 'make', 'ambitious', 'bet', 'ai', 'struggle', 'drive', 'value', 'core', 'business', 'remain', 'cautious', 'overzealous', 'good', 'first', 'step', 'exist', 'machine', 'learn', 'engineer', 'even', 'talented', 'data', 'scientist', 'manage']\n",
      "\n",
      "Tokens: ['To', 'take', 'the', 'next', 'step', ',', 'again', ',', 'identify', 'your', 'data', 'assets', '.', 'Many', 'sectors', ',', 'and', 'even', 'divisions', 'within', 'your', 'organization', ',', 'use', 'highly', 'specialized', 'vocabularies', '.', 'Through', 'a', 'combination', 'of', 'your', 'data', 'assets', 'and', 'open', 'datasets', ',', 'train', 'a', 'model', 'for', 'the', 'needs', 'of', 'specific', 'sectors', 'or', 'divisions', '.', 'Think', 'of', 'finance', '.', 'You', 'do', 'not', 'want', 'a', 'model', 'specialized', 'in', 'finance', '.', 'You', 'want', 'a', 'model', 'customized', 'for', 'commercial', 'banking', ',', 'or', 'for', 'capital', 'markets', '.', 'And', 'data', 'is', 'critical', ',', 'but', 'now', 'it', 'is', 'unlabeled', 'data', ',', 'and', 'the', 'more', 'the', 'better', '.', 'Specialized', 'models', 'like', 'this', 'can', 'unlock', 'untold', 'value', 'for', 'your', 'firm', '.']\n",
      "Tokens after punctuation removal: ['to', 'take', 'the', 'next', 'step', 'again', 'identify', 'your', 'data', 'assets', 'many', 'sectors', 'and', 'even', 'divisions', 'within', 'your', 'organization', 'use', 'highly', 'specialized', 'vocabularies', 'through', 'a', 'combination', 'of', 'your', 'data', 'assets', 'and', 'open', 'datasets', 'train', 'a', 'model', 'for', 'the', 'needs', 'of', 'specific', 'sectors', 'or', 'divisions', 'think', 'of', 'finance', 'you', 'do', 'not', 'want', 'a', 'model', 'specialized', 'in', 'finance', 'you', 'want', 'a', 'model', 'customized', 'for', 'commercial', 'banking', 'or', 'for', 'capital', 'markets', 'and', 'data', 'is', 'critical', 'but', 'now', 'it', 'is', 'unlabeled', 'data', 'and', 'the', 'more', 'the', 'better', 'specialized', 'models', 'like', 'this', 'can', 'unlock', 'untold', 'value', 'for', 'your', 'firm']\n",
      "Tokens after stopword removal: ['take', 'next', 'step', 'identify', 'data', 'assets', 'many', 'sectors', 'even', 'divisions', 'within', 'organization', 'use', 'highly', 'specialized', 'vocabularies', 'combination', 'data', 'assets', 'open', 'datasets', 'train', 'model', 'needs', 'specific', 'sectors', 'divisions', 'think', 'finance', 'want', 'model', 'specialized', 'finance', 'want', 'model', 'customized', 'commercial', 'banking', 'capital', 'markets', 'data', 'critical', 'unlabeled', 'data', 'better', 'specialized', 'models', 'like', 'unlock', 'untold', 'value', 'firm']\n",
      "POS tags: [('take', 'VB'), ('next', 'JJ'), ('step', 'NN'), ('identify', 'VB'), ('data', 'NNS'), ('assets', 'NNS'), ('many', 'JJ'), ('sectors', 'NNS'), ('even', 'RB'), ('divisions', 'NNS'), ('within', 'IN'), ('organization', 'NN'), ('use', 'NN'), ('highly', 'RB'), ('specialized', 'JJ'), ('vocabularies', 'NNS'), ('combination', 'NN'), ('data', 'NNS'), ('assets', 'NNS'), ('open', 'JJ'), ('datasets', 'NNS'), ('train', 'VBP'), ('model', 'NN'), ('needs', 'NNS'), ('specific', 'JJ'), ('sectors', 'NNS'), ('divisions', 'NNS'), ('think', 'VBP'), ('finance', 'NN'), ('want', 'VBP'), ('model', 'NN'), ('specialized', 'VBN'), ('finance', 'NN'), ('want', 'VBP'), ('model', 'NN'), ('customized', 'VBN'), ('commercial', 'JJ'), ('banking', 'NN'), ('capital', 'NN'), ('markets', 'NNS'), ('data', 'RB'), ('critical', 'JJ'), ('unlabeled', 'VBD'), ('data', 'NNS'), ('better', 'RBR'), ('specialized', 'JJ'), ('models', 'NNS'), ('like', 'IN'), ('unlock', 'NN'), ('untold', 'JJ'), ('value', 'NN'), ('firm', 'NN')]\n",
      "Tokens after lemmatization: ['take', 'next', 'step', 'identify', 'data', 'asset', 'many', 'sector', 'even', 'division', 'within', 'organization', 'use', 'highly', 'specialized', 'vocabulary', 'combination', 'data', 'asset', 'open', 'datasets', 'train', 'model', 'need', 'specific', 'sector', 'division', 'think', 'finance', 'want', 'model', 'specialize', 'finance', 'want', 'model', 'customize', 'commercial', 'banking', 'capital', 'market', 'data', 'critical', 'unlabeled', 'data', 'well', 'specialized', 'model', 'like', 'unlock', 'untold', 'value', 'firm']\n",
      "\n",
      "Tokens: ['Understand', 'how', 'you', 'might', 'leverage', 'AI-based', 'language', 'technologies', 'to', 'make', 'better', 'decisions', 'or', 'reorganize', 'your', 'skilled', 'labor', '.']\n",
      "Tokens after punctuation removal: ['understand', 'how', 'you', 'might', 'leverage', 'language', 'technologies', 'to', 'make', 'better', 'decisions', 'or', 'reorganize', 'your', 'skilled', 'labor']\n",
      "Tokens after stopword removal: ['understand', 'might', 'leverage', 'language', 'technologies', 'make', 'better', 'decisions', 'reorganize', 'skilled', 'labor']\n",
      "POS tags: [('understand', 'NN'), ('might', 'MD'), ('leverage', 'VB'), ('language', 'NN'), ('technologies', 'NNS'), ('make', 'VBP'), ('better', 'JJR'), ('decisions', 'NNS'), ('reorganize', 'VB'), ('skilled', 'VBN'), ('labor', 'NN')]\n",
      "Tokens after lemmatization: ['understand', 'might', 'leverage', 'language', 'technology', 'make', 'good', 'decision', 'reorganize', 'skilled', 'labor']\n",
      "\n",
      "Tokens: ['Language-based', 'AI', 'won', '’', 't', 'replace', 'jobs', ',', 'but', 'it', 'will', 'automate', 'many', 'tasks', ',', 'even', 'for', 'decision', 'makers', '.', 'Startups', 'like', 'Verneek', 'are', 'creating', 'Elicit-like', 'tools', 'to', 'enable', 'everyone', 'to', 'make', 'data-informed', 'decisions', '.', 'These', 'new', 'tools', 'will', 'transcend', 'traditional', 'business', 'intelligence', 'and', 'will', 'transform', 'the', 'nature', 'of', 'many', 'roles', 'in', 'organizations', '—', 'programmers', 'are', 'just', 'the', 'beginning', '.']\n",
      "Tokens after punctuation removal: ['ai', 'won', 't', 'replace', 'jobs', 'but', 'it', 'will', 'automate', 'many', 'tasks', 'even', 'for', 'decision', 'makers', 'startups', 'like', 'verneek', 'are', 'creating', 'tools', 'to', 'enable', 'everyone', 'to', 'make', 'decisions', 'these', 'new', 'tools', 'will', 'transcend', 'traditional', 'business', 'intelligence', 'and', 'will', 'transform', 'the', 'nature', 'of', 'many', 'roles', 'in', 'organizations', 'programmers', 'are', 'just', 'the', 'beginning']\n",
      "Tokens after stopword removal: ['ai', 'replace', 'jobs', 'automate', 'many', 'tasks', 'even', 'decision', 'makers', 'startups', 'like', 'verneek', 'creating', 'tools', 'enable', 'everyone', 'make', 'decisions', 'new', 'tools', 'transcend', 'traditional', 'business', 'intelligence', 'transform', 'nature', 'many', 'roles', 'organizations', 'programmers', 'beginning']\n",
      "POS tags: [('ai', 'RB'), ('replace', 'VB'), ('jobs', 'NNS'), ('automate', 'VBP'), ('many', 'JJ'), ('tasks', 'NNS'), ('even', 'RB'), ('decision', 'NN'), ('makers', 'NNS'), ('startups', 'VBP'), ('like', 'IN'), ('verneek', 'NN'), ('creating', 'VBG'), ('tools', 'NNS'), ('enable', 'JJ'), ('everyone', 'NN'), ('make', 'VBP'), ('decisions', 'NNS'), ('new', 'JJ'), ('tools', 'NNS'), ('transcend', 'VBP'), ('traditional', 'JJ'), ('business', 'NN'), ('intelligence', 'NN'), ('transform', 'NN'), ('nature', 'NN'), ('many', 'JJ'), ('roles', 'NNS'), ('organizations', 'NNS'), ('programmers', 'NNS'), ('beginning', 'VBG')]\n",
      "Tokens after lemmatization: ['ai', 'replace', 'job', 'automate', 'many', 'task', 'even', 'decision', 'maker', 'startups', 'like', 'verneek', 'create', 'tool', 'enable', 'everyone', 'make', 'decision', 'new', 'tool', 'transcend', 'traditional', 'business', 'intelligence', 'transform', 'nature', 'many', 'role', 'organization', 'programmer', 'begin']\n",
      "\n",
      "Tokens: ['You', 'need', 'to', 'start', 'understanding', 'how', 'these', 'technologies', 'can', 'be', 'used', 'to', 'reorganize', 'your', 'skilled', 'labor', '.', 'The', 'next', 'generation', 'of', 'tools', 'like', 'OpenAI', '’', 's', 'Codex', 'will', 'lead', 'to', 'more', 'productive', 'programmers', ',', 'which', 'likely', 'means', 'fewer', 'dedicated', 'programmers', 'and', 'more', 'employees', 'with', 'modest', 'programming', 'skills', 'using', 'them', 'for', 'an', 'increasing', 'number', 'of', 'more', 'complex', 'tasks', '.', 'This', 'may', 'not', 'be', 'true', 'for', 'all', 'software', 'developers', ',', 'but', 'it', 'has', 'significant', 'implications', 'for', 'tasks', 'like', 'data', 'processing', 'and', 'web', 'development', '.']\n",
      "Tokens after punctuation removal: ['you', 'need', 'to', 'start', 'understanding', 'how', 'these', 'technologies', 'can', 'be', 'used', 'to', 'reorganize', 'your', 'skilled', 'labor', 'the', 'next', 'generation', 'of', 'tools', 'like', 'openai', 's', 'codex', 'will', 'lead', 'to', 'more', 'productive', 'programmers', 'which', 'likely', 'means', 'fewer', 'dedicated', 'programmers', 'and', 'more', 'employees', 'with', 'modest', 'programming', 'skills', 'using', 'them', 'for', 'an', 'increasing', 'number', 'of', 'more', 'complex', 'tasks', 'this', 'may', 'not', 'be', 'true', 'for', 'all', 'software', 'developers', 'but', 'it', 'has', 'significant', 'implications', 'for', 'tasks', 'like', 'data', 'processing', 'and', 'web', 'development']\n",
      "Tokens after stopword removal: ['need', 'start', 'understanding', 'technologies', 'used', 'reorganize', 'skilled', 'labor', 'next', 'generation', 'tools', 'like', 'openai', 'codex', 'lead', 'productive', 'programmers', 'likely', 'means', 'fewer', 'dedicated', 'programmers', 'employees', 'modest', 'programming', 'skills', 'using', 'increasing', 'number', 'complex', 'tasks', 'may', 'true', 'software', 'developers', 'significant', 'implications', 'tasks', 'like', 'data', 'processing', 'web', 'development']\n",
      "POS tags: [('need', 'JJ'), ('start', 'VBP'), ('understanding', 'VBG'), ('technologies', 'NNS'), ('used', 'VBN'), ('reorganize', 'VB'), ('skilled', 'JJ'), ('labor', 'NN'), ('next', 'JJ'), ('generation', 'NN'), ('tools', 'NNS'), ('like', 'IN'), ('openai', 'JJ'), ('codex', 'NN'), ('lead', 'NN'), ('productive', 'NN'), ('programmers', 'NNS'), ('likely', 'JJ'), ('means', 'VBZ'), ('fewer', 'JJR'), ('dedicated', 'JJ'), ('programmers', 'NNS'), ('employees', 'NNS'), ('modest', 'JJ'), ('programming', 'VBG'), ('skills', 'NNS'), ('using', 'VBG'), ('increasing', 'VBG'), ('number', 'NN'), ('complex', 'JJ'), ('tasks', 'NNS'), ('may', 'MD'), ('true', 'JJ'), ('software', 'NN'), ('developers', 'NNS'), ('significant', 'JJ'), ('implications', 'NNS'), ('tasks', 'NNS'), ('like', 'IN'), ('data', 'NNS'), ('processing', 'VBG'), ('web', 'NN'), ('development', 'NN')]\n",
      "Tokens after lemmatization: ['need', 'start', 'understand', 'technology', 'use', 'reorganize', 'skilled', 'labor', 'next', 'generation', 'tool', 'like', 'openai', 'codex', 'lead', 'productive', 'programmer', 'likely', 'mean', 'few', 'dedicated', 'programmer', 'employee', 'modest', 'program', 'skill', 'use', 'increase', 'number', 'complex', 'task', 'may', 'true', 'software', 'developer', 'significant', 'implication', 'task', 'like', 'data', 'process', 'web', 'development']\n",
      "\n",
      "Tokens: ['Begin', 'incorporating', 'new', 'language-based', 'AI', 'tools', 'for', 'a', 'variety', 'of', 'tasks', 'to', 'better', 'understand', 'their', 'capabilities', '.']\n",
      "Tokens after punctuation removal: ['begin', 'incorporating', 'new', 'ai', 'tools', 'for', 'a', 'variety', 'of', 'tasks', 'to', 'better', 'understand', 'their', 'capabilities']\n",
      "Tokens after stopword removal: ['begin', 'incorporating', 'new', 'ai', 'tools', 'variety', 'tasks', 'better', 'understand', 'capabilities']\n",
      "POS tags: [('begin', 'VB'), ('incorporating', 'VBG'), ('new', 'JJ'), ('ai', 'NN'), ('tools', 'NNS'), ('variety', 'NN'), ('tasks', 'NNS'), ('better', 'RBR'), ('understand', 'VBP'), ('capabilities', 'NNS')]\n",
      "Tokens after lemmatization: ['begin', 'incorporate', 'new', 'ai', 'tool', 'variety', 'task', 'well', 'understand', 'capability']\n",
      "\n",
      "Tokens: ['Right', 'now', 'tools', 'like', 'Elicit', 'are', 'just', 'emerging', ',', 'but', 'they', 'can', 'already', 'be', 'useful', 'in', 'surprising', 'ways', '.', 'In', 'fact', ',', 'the', 'previous', 'suggestion', 'was', 'inspired', 'by', 'one', 'of', 'Elicit', '’', 's', 'brainstorming', 'tasks', 'conditioned', 'on', 'my', 'other', 'three', 'suggestions', '.', 'The', 'original', 'suggestion', 'itself', 'wasn', '’', 't', 'perfect', ',', 'but', 'it', 'reminded', 'me', 'of', 'some', 'critical', 'topics', 'that', 'I', 'had', 'overlooked', ',', 'and', 'I', 'revised', 'the', 'article', 'accordingly', '.', 'In', 'organizations', ',', 'tasks', 'like', 'this', 'can', 'assist', 'strategic', 'thinking', 'or', 'scenario-planning', 'exercises', '.', 'Although', 'there', 'is', 'tremendous', 'potential', 'for', 'such', 'applications', ',', 'right', 'now', 'the', 'results', 'are', 'still', 'relatively', 'crude', ',', 'but', 'they', 'can', 'already', 'add', 'value', 'in', 'their', 'current', 'state', '.']\n",
      "Tokens after punctuation removal: ['right', 'now', 'tools', 'like', 'elicit', 'are', 'just', 'emerging', 'but', 'they', 'can', 'already', 'be', 'useful', 'in', 'surprising', 'ways', 'in', 'fact', 'the', 'previous', 'suggestion', 'was', 'inspired', 'by', 'one', 'of', 'elicit', 's', 'brainstorming', 'tasks', 'conditioned', 'on', 'my', 'other', 'three', 'suggestions', 'the', 'original', 'suggestion', 'itself', 'wasn', 't', 'perfect', 'but', 'it', 'reminded', 'me', 'of', 'some', 'critical', 'topics', 'that', 'i', 'had', 'overlooked', 'and', 'i', 'revised', 'the', 'article', 'accordingly', 'in', 'organizations', 'tasks', 'like', 'this', 'can', 'assist', 'strategic', 'thinking', 'or', 'exercises', 'although', 'there', 'is', 'tremendous', 'potential', 'for', 'such', 'applications', 'right', 'now', 'the', 'results', 'are', 'still', 'relatively', 'crude', 'but', 'they', 'can', 'already', 'add', 'value', 'in', 'their', 'current', 'state']\n",
      "Tokens after stopword removal: ['right', 'tools', 'like', 'elicit', 'emerging', 'already', 'useful', 'surprising', 'ways', 'fact', 'previous', 'suggestion', 'inspired', 'one', 'elicit', 'brainstorming', 'tasks', 'conditioned', 'three', 'suggestions', 'original', 'suggestion', 'perfect', 'reminded', 'critical', 'topics', 'overlooked', 'revised', 'article', 'accordingly', 'organizations', 'tasks', 'like', 'assist', 'strategic', 'thinking', 'exercises', 'although', 'tremendous', 'potential', 'applications', 'right', 'results', 'still', 'relatively', 'crude', 'already', 'add', 'value', 'current', 'state']\n",
      "POS tags: [('right', 'JJ'), ('tools', 'NNS'), ('like', 'IN'), ('elicit', 'JJ'), ('emerging', 'VBG'), ('already', 'RB'), ('useful', 'JJ'), ('surprising', 'JJ'), ('ways', 'NNS'), ('fact', 'NN'), ('previous', 'JJ'), ('suggestion', 'NN'), ('inspired', 'VBD'), ('one', 'CD'), ('elicit', 'NN'), ('brainstorming', 'NN'), ('tasks', 'NNS'), ('conditioned', 'VBD'), ('three', 'CD'), ('suggestions', 'NNS'), ('original', 'JJ'), ('suggestion', 'NN'), ('perfect', 'NN'), ('reminded', 'VBD'), ('critical', 'JJ'), ('topics', 'NNS'), ('overlooked', 'VBD'), ('revised', 'JJ'), ('article', 'NN'), ('accordingly', 'RB'), ('organizations', 'NNS'), ('tasks', 'NNS'), ('like', 'IN'), ('assist', 'JJ'), ('strategic', 'JJ'), ('thinking', 'NN'), ('exercises', 'NNS'), ('although', 'IN'), ('tremendous', 'JJ'), ('potential', 'JJ'), ('applications', 'NNS'), ('right', 'JJ'), ('results', 'NNS'), ('still', 'RB'), ('relatively', 'RB'), ('crude', 'JJ'), ('already', 'RB'), ('add', 'VBP'), ('value', 'NN'), ('current', 'JJ'), ('state', 'NN')]\n",
      "Tokens after lemmatization: ['right', 'tool', 'like', 'elicit', 'emerge', 'already', 'useful', 'surprising', 'way', 'fact', 'previous', 'suggestion', 'inspire', 'one', 'elicit', 'brainstorming', 'task', 'condition', 'three', 'suggestion', 'original', 'suggestion', 'perfect', 'remind', 'critical', 'topic', 'overlook', 'revised', 'article', 'accordingly', 'organization', 'task', 'like', 'assist', 'strategic', 'thinking', 'exercise', 'although', 'tremendous', 'potential', 'application', 'right', 'result', 'still', 'relatively', 'crude', 'already', 'add', 'value', 'current', 'state']\n",
      "\n",
      "Tokens: ['The', 'bottom', 'line', 'is', 'that', 'you', 'need', 'to', 'encourage', 'broad', 'adoption', 'of', 'language-based', 'AI', 'tools', 'throughout', 'your', 'business', '.', 'It', 'is', 'difficult', 'to', 'anticipate', 'just', 'how', 'these', 'tools', 'might', 'be', 'used', 'at', 'different', 'levels', 'of', 'your', 'organization', ',', 'but', 'the', 'best', 'way', 'to', 'get', 'an', 'understanding', 'of', 'this', 'tech', 'may', 'be', 'for', 'you', 'and', 'other', 'leaders', 'in', 'your', 'firm', 'to', 'adopt', 'it', 'yourselves', '.', 'Don', '’', 't', 'bet', 'the', 'boat', 'on', 'it', 'because', 'some', 'of', 'the', 'tech', 'may', 'not', 'work', 'out', ',', 'but', 'if', 'your', 'team', 'gains', 'a', 'better', 'understanding', 'of', 'what', 'is', 'possible', ',', 'then', 'you', 'will', 'be', 'ahead', 'of', 'the', 'competition', '.', 'Remember', 'that', 'while', 'current', 'AI', 'might', 'not', 'be', 'poised', 'to', 'replace', 'managers', ',', 'managers', 'who', 'understand', 'AI', 'are', 'poised', 'to', 'replace', 'managers', 'who', 'don', '’', 't', '.']\n",
      "Tokens after punctuation removal: ['the', 'bottom', 'line', 'is', 'that', 'you', 'need', 'to', 'encourage', 'broad', 'adoption', 'of', 'ai', 'tools', 'throughout', 'your', 'business', 'it', 'is', 'difficult', 'to', 'anticipate', 'just', 'how', 'these', 'tools', 'might', 'be', 'used', 'at', 'different', 'levels', 'of', 'your', 'organization', 'but', 'the', 'best', 'way', 'to', 'get', 'an', 'understanding', 'of', 'this', 'tech', 'may', 'be', 'for', 'you', 'and', 'other', 'leaders', 'in', 'your', 'firm', 'to', 'adopt', 'it', 'yourselves', 'don', 't', 'bet', 'the', 'boat', 'on', 'it', 'because', 'some', 'of', 'the', 'tech', 'may', 'not', 'work', 'out', 'but', 'if', 'your', 'team', 'gains', 'a', 'better', 'understanding', 'of', 'what', 'is', 'possible', 'then', 'you', 'will', 'be', 'ahead', 'of', 'the', 'competition', 'remember', 'that', 'while', 'current', 'ai', 'might', 'not', 'be', 'poised', 'to', 'replace', 'managers', 'managers', 'who', 'understand', 'ai', 'are', 'poised', 'to', 'replace', 'managers', 'who', 'don', 't']\n",
      "Tokens after stopword removal: ['bottom', 'line', 'need', 'encourage', 'broad', 'adoption', 'ai', 'tools', 'throughout', 'business', 'difficult', 'anticipate', 'tools', 'might', 'used', 'different', 'levels', 'organization', 'best', 'way', 'get', 'understanding', 'tech', 'may', 'leaders', 'firm', 'adopt', 'bet', 'boat', 'tech', 'may', 'work', 'team', 'gains', 'better', 'understanding', 'possible', 'ahead', 'competition', 'remember', 'current', 'ai', 'might', 'poised', 'replace', 'managers', 'managers', 'understand', 'ai', 'poised', 'replace', 'managers']\n",
      "POS tags: [('bottom', 'NN'), ('line', 'NN'), ('need', 'VBP'), ('encourage', 'VB'), ('broad', 'JJ'), ('adoption', 'NN'), ('ai', 'NN'), ('tools', 'NNS'), ('throughout', 'IN'), ('business', 'NN'), ('difficult', 'JJ'), ('anticipate', 'NN'), ('tools', 'NNS'), ('might', 'MD'), ('used', 'VBN'), ('different', 'JJ'), ('levels', 'NNS'), ('organization', 'NN'), ('best', 'JJS'), ('way', 'NN'), ('get', 'VB'), ('understanding', 'JJ'), ('tech', 'NN'), ('may', 'MD'), ('leaders', 'NNS'), ('firm', 'VB'), ('adopt', 'RB'), ('bet', 'RB'), ('boat', 'NN'), ('tech', 'NN'), ('may', 'MD'), ('work', 'VB'), ('team', 'NN'), ('gains', 'NNS'), ('better', 'RBR'), ('understanding', 'VBG'), ('possible', 'JJ'), ('ahead', 'RB'), ('competition', 'NN'), ('remember', 'VB'), ('current', 'JJ'), ('ai', 'NN'), ('might', 'MD'), ('poised', 'VBN'), ('replace', 'VB'), ('managers', 'NNS'), ('managers', 'NNS'), ('understand', 'VBP'), ('ai', 'NNS'), ('poised', 'VBD'), ('replace', 'VB'), ('managers', 'NNS')]\n",
      "Tokens after lemmatization: ['bottom', 'line', 'need', 'encourage', 'broad', 'adoption', 'ai', 'tool', 'throughout', 'business', 'difficult', 'anticipate', 'tool', 'might', 'use', 'different', 'level', 'organization', 'best', 'way', 'get', 'understanding', 'tech', 'may', 'leader', 'firm', 'adopt', 'bet', 'boat', 'tech', 'may', 'work', 'team', 'gain', 'well', 'understand', 'possible', 'ahead', 'competition', 'remember', 'current', 'ai', 'might', 'poise', 'replace', 'manager', 'manager', 'understand', 'ai', 'poise', 'replace', 'manager']\n",
      "\n",
      "Tokens: ['Do', 'not', 'underestimate', 'the', 'transformative', 'potential', 'of', 'AI', '.']\n",
      "Tokens after punctuation removal: ['do', 'not', 'underestimate', 'the', 'transformative', 'potential', 'of', 'ai']\n",
      "Tokens after stopword removal: ['underestimate', 'transformative', 'potential', 'ai']\n",
      "POS tags: [('underestimate', 'JJ'), ('transformative', 'JJ'), ('potential', 'NN'), ('ai', 'NN')]\n",
      "Tokens after lemmatization: ['underestimate', 'transformative', 'potential', 'ai']\n",
      "\n",
      "Tokens: ['Large', 'foundation', 'models', 'like', 'GPT-3', 'exhibit', 'abilities', 'to', 'generalize', 'to', 'a', 'large', 'number', 'of', 'tasks', 'without', 'any', 'task-specific', 'training', '.', 'The', 'recent', 'progress', 'in', 'this', 'tech', 'is', 'a', 'significant', 'step', 'toward', 'human-level', 'generalization', 'and', 'general', 'artificial', 'intelligence', 'that', 'are', 'the', 'ultimate', 'goals', 'of', 'many', 'AI', 'researchers', ',', 'including', 'those', 'at', 'OpenAI', 'and', 'Google', '’', 's', 'DeepMind', '.', 'Such', 'systems', 'have', 'tremendous', 'disruptive', 'potential', 'that', 'could', 'lead', 'to', 'AI-driven', 'explosive', 'economic', 'growth', ',', 'which', 'would', 'radically', 'transform', 'business', 'and', 'society', '.', 'While', 'you', 'may', 'still', 'be', 'skeptical', 'of', 'radically', 'transformative', 'AI', 'like', 'artificial', 'general', 'intelligence', ',', 'it', 'is', 'prudent', 'for', 'organizations', '’', 'leaders', 'to', 'be', 'cognizant', 'of', 'early', 'signs', 'of', 'progress', 'due', 'to', 'its', 'tremendous', 'disruptive', 'potential', '.']\n",
      "Tokens after punctuation removal: ['large', 'foundation', 'models', 'like', 'exhibit', 'abilities', 'to', 'generalize', 'to', 'a', 'large', 'number', 'of', 'tasks', 'without', 'any', 'training', 'the', 'recent', 'progress', 'in', 'this', 'tech', 'is', 'a', 'significant', 'step', 'toward', 'generalization', 'and', 'general', 'artificial', 'intelligence', 'that', 'are', 'the', 'ultimate', 'goals', 'of', 'many', 'ai', 'researchers', 'including', 'those', 'at', 'openai', 'and', 'google', 's', 'deepmind', 'such', 'systems', 'have', 'tremendous', 'disruptive', 'potential', 'that', 'could', 'lead', 'to', 'explosive', 'economic', 'growth', 'which', 'would', 'radically', 'transform', 'business', 'and', 'society', 'while', 'you', 'may', 'still', 'be', 'skeptical', 'of', 'radically', 'transformative', 'ai', 'like', 'artificial', 'general', 'intelligence', 'it', 'is', 'prudent', 'for', 'organizations', 'leaders', 'to', 'be', 'cognizant', 'of', 'early', 'signs', 'of', 'progress', 'due', 'to', 'its', 'tremendous', 'disruptive', 'potential']\n",
      "Tokens after stopword removal: ['large', 'foundation', 'models', 'like', 'exhibit', 'abilities', 'generalize', 'large', 'number', 'tasks', 'without', 'training', 'recent', 'progress', 'tech', 'significant', 'step', 'toward', 'generalization', 'general', 'artificial', 'intelligence', 'ultimate', 'goals', 'many', 'ai', 'researchers', 'including', 'openai', 'google', 'deepmind', 'systems', 'tremendous', 'disruptive', 'potential', 'could', 'lead', 'explosive', 'economic', 'growth', 'would', 'radically', 'transform', 'business', 'society', 'may', 'still', 'skeptical', 'radically', 'transformative', 'ai', 'like', 'artificial', 'general', 'intelligence', 'prudent', 'organizations', 'leaders', 'cognizant', 'early', 'signs', 'progress', 'due', 'tremendous', 'disruptive', 'potential']\n",
      "POS tags: [('large', 'JJ'), ('foundation', 'NN'), ('models', 'NNS'), ('like', 'IN'), ('exhibit', 'NN'), ('abilities', 'NNS'), ('generalize', 'VBP'), ('large', 'JJ'), ('number', 'NN'), ('tasks', 'NNS'), ('without', 'IN'), ('training', 'VBG'), ('recent', 'JJ'), ('progress', 'NN'), ('tech', 'NN'), ('significant', 'JJ'), ('step', 'NN'), ('toward', 'IN'), ('generalization', 'NN'), ('general', 'JJ'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('ultimate', 'JJ'), ('goals', 'NNS'), ('many', 'JJ'), ('ai', 'VBP'), ('researchers', 'NNS'), ('including', 'VBG'), ('openai', 'JJ'), ('google', 'NN'), ('deepmind', 'NN'), ('systems', 'NNS'), ('tremendous', 'JJ'), ('disruptive', 'JJ'), ('potential', 'NN'), ('could', 'MD'), ('lead', 'VB'), ('explosive', 'JJ'), ('economic', 'JJ'), ('growth', 'NN'), ('would', 'MD'), ('radically', 'RB'), ('transform', 'VB'), ('business', 'NN'), ('society', 'NN'), ('may', 'MD'), ('still', 'RB'), ('skeptical', 'VB'), ('radically', 'RB'), ('transformative', 'JJ'), ('ai', 'NNS'), ('like', 'IN'), ('artificial', 'JJ'), ('general', 'JJ'), ('intelligence', 'NN'), ('prudent', 'JJ'), ('organizations', 'NNS'), ('leaders', 'NNS'), ('cognizant', 'VBP'), ('early', 'JJ'), ('signs', 'NNS'), ('progress', 'NN'), ('due', 'JJ'), ('tremendous', 'JJ'), ('disruptive', 'JJ'), ('potential', 'NN')]\n",
      "Tokens after lemmatization: ['large', 'foundation', 'model', 'like', 'exhibit', 'ability', 'generalize', 'large', 'number', 'task', 'without', 'train', 'recent', 'progress', 'tech', 'significant', 'step', 'toward', 'generalization', 'general', 'artificial', 'intelligence', 'ultimate', 'goal', 'many', 'ai', 'researcher', 'include', 'openai', 'google', 'deepmind', 'system', 'tremendous', 'disruptive', 'potential', 'could', 'lead', 'explosive', 'economic', 'growth', 'would', 'radically', 'transform', 'business', 'society', 'may', 'still', 'skeptical', 'radically', 'transformative', 'ai', 'like', 'artificial', 'general', 'intelligence', 'prudent', 'organization', 'leader', 'cognizant', 'early', 'sign', 'progress', 'due', 'tremendous', 'disruptive', 'potential']\n",
      "\n",
      "Tokens: ['Consider', 'that', 'former', 'Google', 'chief', 'Eric', 'Schmidt', 'expects', 'general', 'artificial', 'intelligence', 'in', '10–20', 'years', 'and', 'that', 'the', 'UK', 'recently', 'took', 'an', 'official', 'position', 'on', 'risks', 'from', 'artificial', 'general', 'intelligence', '.', 'Had', 'organizations', 'paid', 'attention', 'to', 'Anthony', 'Fauci', '’', 's', '2017', 'warning', 'on', 'the', 'importance', 'of', 'pandemic', 'preparedness', ',', 'the', 'most', 'severe', 'effects', 'of', 'the', 'pandemic', 'and', 'ensuing', 'supply', 'chain', 'crisis', 'may', 'have', 'been', 'avoided', '.', 'Ignoring', 'the', 'transformative', 'potential', 'of', 'AI', 'also', 'carries', 'risks', ',', 'and', 'similar', 'to', 'the', 'supply', 'chain', 'crisis', ',', 'firms', '’', 'inaction', 'or', 'irresponsible', 'use', 'of', 'AI', 'could', 'have', 'widespread', 'and', 'damaging', 'effects', 'on', 'society', '(', 'e.g.', ',', 'increasing', 'inequality', 'or', 'domain-specific', 'risks', 'from', 'automation', ')', '.', 'However', ',', 'unlike', 'the', 'supply', 'chain', 'crisis', ',', 'societal', 'changes', 'from', 'transformative', 'AI', 'will', 'likely', 'be', 'irreversible', 'and', 'could', 'even', 'continue', 'to', 'accelerate', '.', 'Organizations', 'should', 'begin', 'preparing', 'now', 'not', 'only', 'to', 'capitalize', 'on', 'transformative', 'AI', ',', 'but', 'to', 'do', 'their', 'part', 'to', 'avoid', 'undesirable', 'futures', 'and', 'ensure', 'that', 'advanced', 'AI', 'is', 'used', 'to', 'equitably', 'benefit', 'society', '.']\n",
      "Tokens after punctuation removal: ['consider', 'that', 'former', 'google', 'chief', 'eric', 'schmidt', 'expects', 'general', 'artificial', 'intelligence', 'in', 'years', 'and', 'that', 'the', 'uk', 'recently', 'took', 'an', 'official', 'position', 'on', 'risks', 'from', 'artificial', 'general', 'intelligence', 'had', 'organizations', 'paid', 'attention', 'to', 'anthony', 'fauci', 's', '2017', 'warning', 'on', 'the', 'importance', 'of', 'pandemic', 'preparedness', 'the', 'most', 'severe', 'effects', 'of', 'the', 'pandemic', 'and', 'ensuing', 'supply', 'chain', 'crisis', 'may', 'have', 'been', 'avoided', 'ignoring', 'the', 'transformative', 'potential', 'of', 'ai', 'also', 'carries', 'risks', 'and', 'similar', 'to', 'the', 'supply', 'chain', 'crisis', 'firms', 'inaction', 'or', 'irresponsible', 'use', 'of', 'ai', 'could', 'have', 'widespread', 'and', 'damaging', 'effects', 'on', 'society', 'increasing', 'inequality', 'or', 'risks', 'from', 'automation', 'however', 'unlike', 'the', 'supply', 'chain', 'crisis', 'societal', 'changes', 'from', 'transformative', 'ai', 'will', 'likely', 'be', 'irreversible', 'and', 'could', 'even', 'continue', 'to', 'accelerate', 'organizations', 'should', 'begin', 'preparing', 'now', 'not', 'only', 'to', 'capitalize', 'on', 'transformative', 'ai', 'but', 'to', 'do', 'their', 'part', 'to', 'avoid', 'undesirable', 'futures', 'and', 'ensure', 'that', 'advanced', 'ai', 'is', 'used', 'to', 'equitably', 'benefit', 'society']\n",
      "Tokens after stopword removal: ['consider', 'former', 'google', 'chief', 'eric', 'schmidt', 'expects', 'general', 'artificial', 'intelligence', 'years', 'uk', 'recently', 'took', 'official', 'position', 'risks', 'artificial', 'general', 'intelligence', 'organizations', 'paid', 'attention', 'anthony', 'fauci', '2017', 'warning', 'importance', 'pandemic', 'preparedness', 'severe', 'effects', 'pandemic', 'ensuing', 'supply', 'chain', 'crisis', 'may', 'avoided', 'ignoring', 'transformative', 'potential', 'ai', 'also', 'carries', 'risks', 'similar', 'supply', 'chain', 'crisis', 'firms', 'inaction', 'irresponsible', 'use', 'ai', 'could', 'widespread', 'damaging', 'effects', 'society', 'increasing', 'inequality', 'risks', 'automation', 'however', 'unlike', 'supply', 'chain', 'crisis', 'societal', 'changes', 'transformative', 'ai', 'likely', 'irreversible', 'could', 'even', 'continue', 'accelerate', 'organizations', 'begin', 'preparing', 'capitalize', 'transformative', 'ai', 'part', 'avoid', 'undesirable', 'futures', 'ensure', 'advanced', 'ai', 'used', 'equitably', 'benefit', 'society']\n",
      "POS tags: [('consider', 'VB'), ('former', 'JJ'), ('google', 'NN'), ('chief', 'NN'), ('eric', 'JJ'), ('schmidt', 'NN'), ('expects', 'VBZ'), ('general', 'JJ'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('years', 'NNS'), ('uk', 'RB'), ('recently', 'RB'), ('took', 'VBD'), ('official', 'JJ'), ('position', 'NN'), ('risks', 'NNS'), ('artificial', 'JJ'), ('general', 'JJ'), ('intelligence', 'NN'), ('organizations', 'NNS'), ('paid', 'VBD'), ('attention', 'NN'), ('anthony', 'NN'), ('fauci', 'NN'), ('2017', 'CD'), ('warning', 'VBG'), ('importance', 'NN'), ('pandemic', 'JJ'), ('preparedness', 'NN'), ('severe', 'JJ'), ('effects', 'NNS'), ('pandemic', 'JJ'), ('ensuing', 'VBG'), ('supply', 'NN'), ('chain', 'NN'), ('crisis', 'NN'), ('may', 'MD'), ('avoided', 'VB'), ('ignoring', 'VBG'), ('transformative', 'JJ'), ('potential', 'NN'), ('ai', 'NN'), ('also', 'RB'), ('carries', 'VBZ'), ('risks', 'NNS'), ('similar', 'JJ'), ('supply', 'NN'), ('chain', 'NN'), ('crisis', 'NN'), ('firms', 'NNS'), ('inaction', 'VBP'), ('irresponsible', 'JJ'), ('use', 'NN'), ('ai', 'NN'), ('could', 'MD'), ('widespread', 'VB'), ('damaging', 'JJ'), ('effects', 'NNS'), ('society', 'NN'), ('increasing', 'VBG'), ('inequality', 'NN'), ('risks', 'NNS'), ('automation', 'VBP'), ('however', 'RB'), ('unlike', 'IN'), ('supply', 'NN'), ('chain', 'NN'), ('crisis', 'NN'), ('societal', 'JJ'), ('changes', 'NNS'), ('transformative', 'VBP'), ('ai', 'NN'), ('likely', 'JJ'), ('irreversible', 'NN'), ('could', 'MD'), ('even', 'RB'), ('continue', 'VB'), ('accelerate', 'JJ'), ('organizations', 'NNS'), ('begin', 'VBP'), ('preparing', 'VBG'), ('capitalize', 'NN'), ('transformative', 'JJ'), ('ai', 'JJ'), ('part', 'NN'), ('avoid', 'NN'), ('undesirable', 'JJ'), ('futures', 'NNS'), ('ensure', 'VB'), ('advanced', 'JJ'), ('ai', 'NNS'), ('used', 'VBN'), ('equitably', 'RB'), ('benefit', 'VB'), ('society', 'NN')]\n",
      "Tokens after lemmatization: ['consider', 'former', 'google', 'chief', 'eric', 'schmidt', 'expect', 'general', 'artificial', 'intelligence', 'year', 'uk', 'recently', 'take', 'official', 'position', 'risk', 'artificial', 'general', 'intelligence', 'organization', 'pay', 'attention', 'anthony', 'fauci', '2017', 'warn', 'importance', 'pandemic', 'preparedness', 'severe', 'effect', 'pandemic', 'ensue', 'supply', 'chain', 'crisis', 'may', 'avoid', 'ignore', 'transformative', 'potential', 'ai', 'also', 'carry', 'risk', 'similar', 'supply', 'chain', 'crisis', 'firm', 'inaction', 'irresponsible', 'use', 'ai', 'could', 'widespread', 'damaging', 'effect', 'society', 'increase', 'inequality', 'risk', 'automation', 'however', 'unlike', 'supply', 'chain', 'crisis', 'societal', 'change', 'transformative', 'ai', 'likely', 'irreversible', 'could', 'even', 'continue', 'accelerate', 'organization', 'begin', 'prepare', 'capitalize', 'transformative', 'ai', 'part', 'avoid', 'undesirable', 'future', 'ensure', 'advanced', 'ai', 'use', 'equitably', 'benefit', 'society']\n",
      "\n",
      "Tokens: ['Language-Based', 'AI', 'Tools', 'Are', 'Here', 'to', 'Stay']\n",
      "Tokens after punctuation removal: ['ai', 'tools', 'are', 'here', 'to', 'stay']\n",
      "Tokens after stopword removal: ['ai', 'tools', 'stay']\n",
      "POS tags: [('ai', 'NN'), ('tools', 'NNS'), ('stay', 'VBP')]\n",
      "Tokens after lemmatization: ['ai', 'tool', 'stay']\n",
      "\n",
      "Tokens: ['Powerful', 'generalizable', 'language-based', 'AI', 'tools', 'like', 'Elicit', 'are', 'here', ',', 'and', 'they', 'are', 'just', 'the', 'tip', 'of', 'the', 'iceberg', ';', 'multimodal', 'foundation', 'model-based', 'tools', 'are', 'poised', 'to', 'transform', 'business', 'in', 'ways', 'that', 'are', 'still', 'difficult', 'to', 'predict', '.', 'To', 'begin', 'preparing', 'now', ',', 'start', 'understanding', 'your', 'text', 'data', 'assets', 'and', 'the', 'variety', 'of', 'cognitive', 'tasks', 'involved', 'in', 'different', 'roles', 'in', 'your', 'organization', '.', 'Aggressively', 'adopt', 'new', 'language-based', 'AI', 'technologies', ';', 'some', 'will', 'work', 'well', 'and', 'others', 'will', 'not', ',', 'but', 'your', 'employees', 'will', 'be', 'quicker', 'to', 'adjust', 'when', 'you', 'move', 'on', 'to', 'the', 'next', '.', 'And', 'don', '’', 't', 'forget', 'to', 'adopt', 'these', 'technologies', 'yourself', '—', 'this', 'is', 'the', 'best', 'way', 'for', 'you', 'to', 'start', 'to', 'understand', 'their', 'future', 'roles', 'in', 'your', 'organization', '.']\n",
      "Tokens after punctuation removal: ['powerful', 'generalizable', 'ai', 'tools', 'like', 'elicit', 'are', 'here', 'and', 'they', 'are', 'just', 'the', 'tip', 'of', 'the', 'iceberg', 'multimodal', 'foundation', 'tools', 'are', 'poised', 'to', 'transform', 'business', 'in', 'ways', 'that', 'are', 'still', 'difficult', 'to', 'predict', 'to', 'begin', 'preparing', 'now', 'start', 'understanding', 'your', 'text', 'data', 'assets', 'and', 'the', 'variety', 'of', 'cognitive', 'tasks', 'involved', 'in', 'different', 'roles', 'in', 'your', 'organization', 'aggressively', 'adopt', 'new', 'ai', 'technologies', 'some', 'will', 'work', 'well', 'and', 'others', 'will', 'not', 'but', 'your', 'employees', 'will', 'be', 'quicker', 'to', 'adjust', 'when', 'you', 'move', 'on', 'to', 'the', 'next', 'and', 'don', 't', 'forget', 'to', 'adopt', 'these', 'technologies', 'yourself', 'this', 'is', 'the', 'best', 'way', 'for', 'you', 'to', 'start', 'to', 'understand', 'their', 'future', 'roles', 'in', 'your', 'organization']\n",
      "Tokens after stopword removal: ['powerful', 'generalizable', 'ai', 'tools', 'like', 'elicit', 'tip', 'iceberg', 'multimodal', 'foundation', 'tools', 'poised', 'transform', 'business', 'ways', 'still', 'difficult', 'predict', 'begin', 'preparing', 'start', 'understanding', 'text', 'data', 'assets', 'variety', 'cognitive', 'tasks', 'involved', 'different', 'roles', 'organization', 'aggressively', 'adopt', 'new', 'ai', 'technologies', 'work', 'well', 'others', 'employees', 'quicker', 'adjust', 'move', 'next', 'forget', 'adopt', 'technologies', 'best', 'way', 'start', 'understand', 'future', 'roles', 'organization']\n",
      "POS tags: [('powerful', 'JJ'), ('generalizable', 'JJ'), ('ai', 'NN'), ('tools', 'NNS'), ('like', 'IN'), ('elicit', 'JJ'), ('tip', 'NN'), ('iceberg', 'NN'), ('multimodal', 'NN'), ('foundation', 'NN'), ('tools', 'NNS'), ('poised', 'VBN'), ('transform', 'NN'), ('business', 'NN'), ('ways', 'NNS'), ('still', 'RB'), ('difficult', 'JJ'), ('predict', 'VBP'), ('begin', 'VB'), ('preparing', 'VBG'), ('start', 'JJ'), ('understanding', 'VBG'), ('text', 'NN'), ('data', 'NNS'), ('assets', 'NNS'), ('variety', 'VBP'), ('cognitive', 'JJ'), ('tasks', 'NNS'), ('involved', 'VBN'), ('different', 'JJ'), ('roles', 'NNS'), ('organization', 'NN'), ('aggressively', 'RB'), ('adopt', 'JJ'), ('new', 'JJ'), ('ai', 'NN'), ('technologies', 'NNS'), ('work', 'VBP'), ('well', 'RB'), ('others', 'NNS'), ('employees', 'NNS'), ('quicker', 'RB'), ('adjust', 'VBP'), ('move', 'VB'), ('next', 'JJ'), ('forget', 'NN'), ('adopt', 'JJ'), ('technologies', 'NNS'), ('best', 'JJS'), ('way', 'NN'), ('start', 'NN'), ('understand', 'VBP'), ('future', 'JJ'), ('roles', 'NNS'), ('organization', 'NN')]\n",
      "Tokens after lemmatization: ['powerful', 'generalizable', 'ai', 'tool', 'like', 'elicit', 'tip', 'iceberg', 'multimodal', 'foundation', 'tool', 'poise', 'transform', 'business', 'way', 'still', 'difficult', 'predict', 'begin', 'prepare', 'start', 'understand', 'text', 'data', 'asset', 'variety', 'cognitive', 'task', 'involve', 'different', 'role', 'organization', 'aggressively', 'adopt', 'new', 'ai', 'technology', 'work', 'well', 'others', 'employee', 'quicker', 'adjust', 'move', 'next', 'forget', 'adopt', 'technology', 'best', 'way', 'start', 'understand', 'future', 'role', 'organization']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences = raw_text.strip().split('\\n')\n",
    "df = pd.DataFrame(sentences, columns=['original'])\n",
    "df['cleaned'] = df['original'].apply(preprocess)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "6f2e93ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>original</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Until recently, the conventional wisdom was th...</td>\n",
       "      <td>recently conventional wisdom ai good human dec...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The most visible advances have been in what’s ...</td>\n",
       "      <td>visible advance call natural language processi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Yet while these stunts may be attention grabbi...</td>\n",
       "      <td>yet stunt may attention grab really indicative...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>What NLP Can Do</td>\n",
       "      <td>nlp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The best known natural language processing too...</td>\n",
       "      <td>best know natural language processing tool ope...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>For businesses, the three areas where GPT-3 ha...</td>\n",
       "      <td>business three area appear promise write cod r...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Models like GPT-3 are considered to be foundat...</td>\n",
       "      <td>model like consider foundation model emerge ai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A Language-Based AI Research Assistant</td>\n",
       "      <td>ai research assistant</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>In my own work, I’ve been looking at how GPT-3...</td>\n",
       "      <td>work look tool assist researcher research proc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>I’ve found — not surprisingly — that Elicit wo...</td>\n",
       "      <td>find surprisingly elicit work well task others...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>For example, the rephrase task is useful for w...</td>\n",
       "      <td>example rephrase task useful write lack integr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>All of this is changing how I work. I spend mu...</td>\n",
       "      <td>change work spend much less time try find exis...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>How Can Organizations Prepare for the Future?</td>\n",
       "      <td>organization prepare future</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Identify your text data assets and determine h...</td>\n",
       "      <td>identify text data asset determine late techni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>You are certainly aware of the value of data, ...</td>\n",
       "      <td>certainly aware value data still may overlook ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>There is so much text data, and you don’t need...</td>\n",
       "      <td>much text data need advanced model like extrac...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>To take the next step, again, identify your da...</td>\n",
       "      <td>take next step identify data asset many sector...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Understand how you might leverage AI-based lan...</td>\n",
       "      <td>understand might leverage language technology ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Language-based AI won’t replace jobs, but it w...</td>\n",
       "      <td>ai replace job automate many task even decisio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>You need to start understanding how these tech...</td>\n",
       "      <td>need start understand technology use reorganiz...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Begin incorporating new language-based AI tool...</td>\n",
       "      <td>begin incorporate new ai tool variety task wel...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Right now tools like Elicit are just emerging,...</td>\n",
       "      <td>right tool like elicit emerge already useful s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>The bottom line is that you need to encourage ...</td>\n",
       "      <td>bottom line need encourage broad adoption ai t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Do not underestimate the transformative potent...</td>\n",
       "      <td>underestimate transformative potential ai</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Large foundation models like GPT-3 exhibit abi...</td>\n",
       "      <td>large foundation model like exhibit ability ge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Consider that former Google chief Eric Schmidt...</td>\n",
       "      <td>consider former google chief eric schmidt expe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Language-Based AI Tools Are Here to Stay</td>\n",
       "      <td>ai tool stay</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Powerful generalizable language-based AI tools...</td>\n",
       "      <td>powerful generalizable ai tool like elicit tip...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             original  \\\n",
       "0   Until recently, the conventional wisdom was th...   \n",
       "1   The most visible advances have been in what’s ...   \n",
       "2   Yet while these stunts may be attention grabbi...   \n",
       "3                                     What NLP Can Do   \n",
       "4   The best known natural language processing too...   \n",
       "5   For businesses, the three areas where GPT-3 ha...   \n",
       "6   Models like GPT-3 are considered to be foundat...   \n",
       "7              A Language-Based AI Research Assistant   \n",
       "8   In my own work, I’ve been looking at how GPT-3...   \n",
       "9   I’ve found — not surprisingly — that Elicit wo...   \n",
       "10  For example, the rephrase task is useful for w...   \n",
       "11  All of this is changing how I work. I spend mu...   \n",
       "12      How Can Organizations Prepare for the Future?   \n",
       "13  Identify your text data assets and determine h...   \n",
       "14  You are certainly aware of the value of data, ...   \n",
       "15  There is so much text data, and you don’t need...   \n",
       "16  To take the next step, again, identify your da...   \n",
       "17  Understand how you might leverage AI-based lan...   \n",
       "18  Language-based AI won’t replace jobs, but it w...   \n",
       "19  You need to start understanding how these tech...   \n",
       "20  Begin incorporating new language-based AI tool...   \n",
       "21  Right now tools like Elicit are just emerging,...   \n",
       "22  The bottom line is that you need to encourage ...   \n",
       "23  Do not underestimate the transformative potent...   \n",
       "24  Large foundation models like GPT-3 exhibit abi...   \n",
       "25  Consider that former Google chief Eric Schmidt...   \n",
       "26           Language-Based AI Tools Are Here to Stay   \n",
       "27  Powerful generalizable language-based AI tools...   \n",
       "\n",
       "                                              cleaned  \n",
       "0   recently conventional wisdom ai good human dec...  \n",
       "1   visible advance call natural language processi...  \n",
       "2   yet stunt may attention grab really indicative...  \n",
       "3                                                 nlp  \n",
       "4   best know natural language processing tool ope...  \n",
       "5   business three area appear promise write cod r...  \n",
       "6   model like consider foundation model emerge ai...  \n",
       "7                               ai research assistant  \n",
       "8   work look tool assist researcher research proc...  \n",
       "9   find surprisingly elicit work well task others...  \n",
       "10  example rephrase task useful write lack integr...  \n",
       "11  change work spend much less time try find exis...  \n",
       "12                        organization prepare future  \n",
       "13  identify text data asset determine late techni...  \n",
       "14  certainly aware value data still may overlook ...  \n",
       "15  much text data need advanced model like extrac...  \n",
       "16  take next step identify data asset many sector...  \n",
       "17  understand might leverage language technology ...  \n",
       "18  ai replace job automate many task even decisio...  \n",
       "19  need start understand technology use reorganiz...  \n",
       "20  begin incorporate new ai tool variety task wel...  \n",
       "21  right tool like elicit emerge already useful s...  \n",
       "22  bottom line need encourage broad adoption ai t...  \n",
       "23          underestimate transformative potential ai  \n",
       "24  large foundation model like exhibit ability ge...  \n",
       "25  consider former google chief eric schmidt expe...  \n",
       "26                                       ai tool stay  \n",
       "27  powerful generalizable ai tool like elicit tip...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21b056",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CSB320x",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
